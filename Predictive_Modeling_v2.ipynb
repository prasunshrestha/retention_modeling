{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import xgboost as xgb\n",
    "from numpy import mean\n",
    "from sklearn import svm as svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score, roc_auc_score, accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "from sklearn.utils import resample\n",
    "random.seed(123)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Size: 22992\n",
      "# of predictors: 326\n"
     ]
    }
   ],
   "source": [
    "# dataset import\n",
    "df = pd.read_csv(\"T2.csv\", low_memory=False)\n",
    "\n",
    "# dataset shape\n",
    "print(\"Sample Size:\", df.shape[0])\n",
    "print(\"# of predictors:\", df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required variables, features, and label\n",
    "\n",
    "req_vars = ['SwellOneExit', 'YearsAsCoach', 'DaysTSubmitNoMissing',\n",
    "       'FitNoMissing', 'RelationshipBuildingNoMissing',\n",
    "       'FinalAchievementNoMissing', 'CommAndPresNoMissing',\n",
    "       'PredModelScoreNoMissing', 'CMProspectRatingNoMissing',\n",
    "       'AgeAtFDOSNoMissing', 'SchoolSelectivityNoMissing',\n",
    "       'CumuGPANoMissing', 'PerseveranceNoMissing', 'FRPLNoMissing',\n",
    "       'YearsSchoolPartnerNoMissing', 'YearsPartnerPartnerNoMissing',\n",
    "       'FirstYearsInSchoolNoMissing', 'SecondYearsInSchoolNoMissing',\n",
    "       'CMsInSchoolNoMissing', 'CertProgramCostNoMissing',\n",
    "       'AvgFirstMonthSalNoMissing', 'RentPropNoMissing',\n",
    "       'AvgRentNoMissing', 'CorpsSizeNoMissing', 'RegPrefLevNoMissing',\n",
    "       'CSI6NoMissing', 'CSI5NoMissing', 'CSI3NoMissing',\n",
    "       'CSI12NoMissing', 'CLI8NoMissing', 'CLI6NoMissing',\n",
    "       'OtherCMsSameCoachNoMissing', 'OtherCMsPrevCoachNoMissing',\n",
    "       'K12TeachNo', 'K12TeachYes', 'K12TeachNull', 'HadFamRespNo',\n",
    "       'HadFamRespYes', 'HadFamRespNull', 'PellGrantNoOrMissing',\n",
    "       'PellGrantYes', 'GenderFemale', 'GenderMale', 'CalcGradStudent',\n",
    "       'CalcJunior', 'CalcProfessional', 'CalcUndergrad', 'CalcUnknown',\n",
    "       'AttendLIC_HS_No', 'AttendLIC_HS_Yes', 'AttendLIC_HS_Unknown',\n",
    "       'GrewUpLIC_No_Or_Unknown', 'GrewUpLIC_Yes',\n",
    "       'LIC_Served_No_Or_Unknown', 'LIC_Served_Yes', 'Eth_Black',\n",
    "       'Eth_Native', 'Eth_AsianAmPacIsl', 'Eth_Latinx',\n",
    "       'Eth_MultiEthMultiRacial', 'Eth_OtherOrUnknown', 'Eth_White',\n",
    "       'VarsitySport_No_Or_Unknown', 'VarsitySport_Yes',\n",
    "       'DeferralRequested', 'DeferralNotRequested', 'Title1No',\n",
    "       'Title1Yes', 'Grade_ECE', 'Grade_HIGH', 'Grade_LOWELEM',\n",
    "       'Grade_MIDDLE', 'Grade_UPPERELEM', 'Grade_Unknown',\n",
    "       'School_Charter', 'School_Public', 'School_Other', 'LGB_NoProtect',\n",
    "       'LGB_LocalProtect', 'LGB_StateProtect', 'TeacherPP_No',\n",
    "       'TeacherPP_Yes', 'Region_Large', 'Region_Medium', 'Region_Small',\n",
    "       'Urbanicity_Both', 'Urbanicity_Rural', 'Urbanicity_Urban',\n",
    "       'COL_High', 'COL_Low', 'COL_Medium', 'MajorTeaching_Match',\n",
    "       'MajorTeaching_Mismatch', 'MajorOffered_Match',\n",
    "       'MajorOffered_Mismatch']\n",
    "\n",
    "df = df[req_vars] # updating the dataframe with only required variables\n",
    "\n",
    "Y = df['SwellOneExit'] # label\n",
    "X = df.drop('SwellOneExit', axis=1) # features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEGCAYAAABPdROvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARO0lEQVR4nO3dfaxlVX3G8e/jjCJWsbwMFGfAITJVQSvKFKmmrUpSadMKWmjG1DLaScYQNNVWE2iTajQ0Wl9QrJCOERlIK1JfCjbValGrrRS8WAoMFBlFYYTCIL6gLVNn/PWPs64cLncuh7vm3DPX+/0kJ2ef39lr77VvJvNkrb3P3qkqJEmar0dNugOSpMXNIJEkdTFIJEldDBJJUheDRJLUZfmkO7DQDjrooFq9evWkuyFJi8o111xzT1WtmO27JRckq1evZmpqatLdkKRFJcm3dvedU1uSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLkvul+17wrFvvGjSXdBe6Jp3nDbpLkgT4YhEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldxhYkSQ5L8vkkNyXZkuSPWv2AJJ9Nckt733+ozVlJtia5OcmLh+rHJrm+fXdukrT6Pkk+0upXJVk9ruORJM1unCOSncCfVNXTgeOBM5IcBZwJXFFVa4Ar2mfad+uAo4ETgfOSLGvbOh/YCKxprxNbfQPw3ao6EjgHePsYj0eSNIuxBUlV3VlVX23L9wE3ASuBk4DNbbXNwMlt+STgkqraUVW3AluB45IcCuxXVVdWVQEXzWgzva2PAidMj1YkSQtjQc6RtCmnZwNXAYdU1Z0wCBvg4LbaSuD2oWbbWm1lW55Zf1CbqtoJfB84cJb9b0wylWRq+/bte+agJEnAAgRJkscDHwNeV1U/mGvVWWo1R32uNg8uVG2qqrVVtXbFihUP12VJ0iMw1iBJ8mgGIfI3VfXxVr6rTVfR3u9u9W3AYUPNVwF3tPqqWeoPapNkOfBE4N49fySSpN0Z51VbAT4I3FRV7x766nJgfVteD1w2VF/XrsQ6gsFJ9avb9Nd9SY5v2zxtRpvpbZ0CfK6dR5EkLZDlY9z284E/AK5Pcm2r/SnwNuDSJBuA24BTAapqS5JLgRsZXPF1RlXtau1OBy4E9gU+1V4wCKqLk2xlMBJZN8bjkSTNYmxBUlX/yuznMABO2E2bs4GzZ6lPAc+YpX4/LYgkSZPhL9slSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSl7EFSZILktyd5Iah2puTfDvJte31W0PfnZVka5Kbk7x4qH5skuvbd+cmSavvk+QjrX5VktXjOhZJ0u6Nc0RyIXDiLPVzquqY9vpHgCRHAeuAo1ub85Isa+ufD2wE1rTX9DY3AN+tqiOBc4C3j+tAJEm7N7YgqaovAveOuPpJwCVVtaOqbgW2AsclORTYr6qurKoCLgJOHmqzuS1/FDhherQiSVo4kzhH8pok17Wpr/1bbSVw+9A621ptZVueWX9Qm6raCXwfOHC2HSbZmGQqydT27dv33JFIkhY8SM4HngIcA9wJvKvVZxtJ1Bz1udo8tFi1qarWVtXaFStWPLIeS5LmtKBBUlV3VdWuqvoJ8AHguPbVNuCwoVVXAXe0+qpZ6g9qk2Q58ERGn0qTJO0hCxok7ZzHtJcC01d0XQ6sa1diHcHgpPrVVXUncF+S49v5j9OAy4barG/LpwCfa+dRJEkLaPm4Npzkw8ALgIOSbAPeBLwgyTEMpqC+CbwaoKq2JLkUuBHYCZxRVbvapk5ncAXYvsCn2gvgg8DFSbYyGImsG9exSJJ2b2xBUlUvn6X8wTnWPxs4e5b6FPCMWer3A6f29FGS1M9ftkuSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqctIQZLkilFqkqSlZ84HWyV5LPA4Bk853B9I+2o/4Elj7pskaRF4uCckvhp4HYPQuIYHguQHwPvH2C9J0iIxZ5BU1XuB9yZ5bVW9b4H6JElaREZ6ZntVvS/J84DVw22q6qIx9UuStEiMFCRJLgaeAlwL7GrlAgwSSVriRgoSYC1wVFXVODsjSVp8Rv0dyQ3AL4yzI5KkxWnUEclBwI1JrgZ2TBer6iVj6ZUkadEYNUjePM5OSJIWr1Gv2vqXcXdEkrQ4jXrV1n0MrtICeAzwaOBHVbXfuDomSVocRh2RPGH4c5KTgePG0iNJ0qIyr7v/VtXfAy/aw32RJC1Co05tvWzo46MY/K7E35RIkka+aut3hpZ3At8ETtrjvZEkLTqjniN51bg7IklanEZ9sNWqJJ9IcneSu5J8LMmqcXdOkrT3G/Vk+4eAyxk8l2Ql8MlWkyQtcaMGyYqq+lBV7WyvC4EVY+yXJGmRGDVI7knyiiTL2usVwHfG2TFJ0uIwapD8IfB7wH8DdwKnAJ6AlySNfPnvW4H1VfVdgCQHAO9kEDCSpCVs1BHJL02HCEBV3Qs8e64GSS5oV3ndMFQ7IMlnk9zS3vcf+u6sJFuT3JzkxUP1Y5Nc3747N0lafZ8kH2n1q5KsHvFYJEl70KhB8qgZ/+kfwMOPZi4ETpxROxO4oqrWAFe0zyQ5ClgHHN3anJdkWWtzPrARWNNe09vcAHy3qo4EzgHePuKxSJL2oFGD5F3Al5O8NclbgC8DfzlXg6r6InDvjPJJwOa2vBk4eah+SVXtqKpbga3AcUkOBfarqivbY34vmtFmelsfBU6YHq1IkhbOqL9svyjJFIMbNQZ4WVXdOI/9HVJVd7Zt3pnk4FZfCfz70HrbWu3HbXlmfbrN7W1bO5N8HzgQuGfmTpNsZDCq4fDDD59HtyVJuzPqyXZacMwnPEYx20ii5qjP1eahxapNwCaAtWvXerNJSdqD5nUb+Q53tekq2vvdrb4NOGxovVXAHa2+apb6g9okWQ48kYdOpUmSxmyhg+RyYH1bXg9cNlRf167EOoLBSfWr2zTYfUmOb+c/TpvRZnpbpwCfa+dRJEkLaOSprUcqyYeBFwAHJdkGvAl4G3Bpkg3AbcCpAFW1JcmlDKbOdgJnVNWutqnTGVwBti/wqfYC+CBwcZKtDEYi68Z1LJKk3RtbkFTVy3fz1Qm7Wf9s4OxZ6lPAM2ap308LIknS5Cz01JYk6WeMQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6jKRIEnyzSTXJ7k2yVSrHZDks0luae/7D61/VpKtSW5O8uKh+rFtO1uTnJskkzgeSVrKJjkieWFVHVNVa9vnM4ErqmoNcEX7TJKjgHXA0cCJwHlJlrU25wMbgTXtdeIC9l+SxN41tXUSsLktbwZOHqpfUlU7qupWYCtwXJJDgf2q6sqqKuCioTaSpAUyqSAp4DNJrkmysdUOqao7Adr7wa2+Erh9qO22VlvZlmfWHyLJxiRTSaa2b9++Bw9DkrR8Qvt9flXdkeRg4LNJ/muOdWc771Fz1B9arNoEbAJYu3btrOtIkuZnIiOSqrqjvd8NfAI4DrirTVfR3u9uq28DDhtqvgq4o9VXzVKXJC2gBQ+SJD+X5AnTy8BvADcAlwPr22rrgcva8uXAuiT7JDmCwUn1q9v0131Jjm9Xa5021EaStEAmMbV1CPCJdqXucuBvq+rTSb4CXJpkA3AbcCpAVW1JcilwI7ATOKOqdrVtnQ5cCOwLfKq9JEkLaMGDpKq+ATxrlvp3gBN20+Zs4OxZ6lPAM/Z0HyVJo9ubLv+VJC1CBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6LJ90ByTtObe95ZmT7oL2Qof/+fVj3b4jEklSF4NEktTFIJEkdTFIJEldDBJJUpdFHyRJTkxyc5KtSc6cdH8kaalZ1EGSZBnwfuA3gaOAlyc5arK9kqSlZVEHCXAcsLWqvlFV/wdcApw04T5J0pKy2H+QuBK4fejzNuC5M1dKshHY2D7+MMnNC9C3peIg4J5Jd2JvkHeun3QX9GD+25z2puyJrTx5d18s9iCZ7a9TDylUbQI2jb87S0+SqapaO+l+SDP5b3PhLPaprW3AYUOfVwF3TKgvkrQkLfYg+QqwJskRSR4DrAMun3CfJGlJWdRTW1W1M8lrgH8ClgEXVNWWCXdrqXHKUHsr/20ukFQ95JSCJEkjW+xTW5KkCTNIJEldDBLNi7em0d4qyQVJ7k5yw6T7slQYJHrEvDWN9nIXAidOuhNLiUGi+fDWNNprVdUXgXsn3Y+lxCDRfMx2a5qVE+qLpAkzSDQfI92aRtLSYJBoPrw1jaSfMkg0H96aRtJPGSR6xKpqJzB9a5qbgEu9NY32Fkk+DFwJPDXJtiQbJt2nn3XeIkWS1MURiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIg1J8mdJtiS5Lsm1SZ7bsa03J3lDW74wySlt+TFJ3pPk60luSXJZklWd+/l26+/06+fnWP8l03dsTnKyN9xUr0X9qF1pT0ryK8BvA8+pqh1JDgIeM4Zd/QXwBOAXq2pXklcBH0/y3Jr/9fjnVNU7R1mxqi7ngR+Qngz8A3DjPPcrOSKRhhwK3FNVOwCq6h5gVZKPAyQ5Kcn/thHFY5N8o9WfkuTTSa5J8qUkT9vdDpI8DngV8Pqq2tX28yFgB/CiJKuT3JTkA21k9Jkk+z7S/bT1/zjJBW35mUluSPK4JK9M8ldJnge8BHhHG8U8pe/Pp6XKIJEe8BngsCRfS3Jekl8Hvgo8u33/q8ANwC8DzwWuavVNwGur6ljgDcB5c+zjSOC2qvrBjPoUcHRbXgO8v6qOBr4H/O4I+3n90LTW51vtPcCRSV4KfAh4dVX9z3SDqvoyg5HJG6vqmKr6+px/HWk3nNqSmqr6YZJjGQTGC4GPAGcCW5M8ncFzWN4N/BqwDPhSkscDzwP+LvnpTZH3mWM3YfY7JQ/Xb62qa9vyNcDqEfbzkKmtqvpJklcC1wF/XVX/Nke/pHkzSKQhbbrpC8AXklwPrAe+xOBpkD8G/pnBE/iWMRgVPAr4XlUdM+IutgJPTvKEqrpvqP4c4JNtecdQfRew7zz2M20N8EPgSY+wnTQyp7akJslTk6wZKh0DfAv4IvA64Mqq2g4cCDwN2NKmqG5NcmrbRpI8a3f7qKofAZuBd7dHFpPkNOBxwOfmaPeI9tPWeSLwXgYjqAOnrxqb4T4GJ/6leTNIpAc8Htic5MYk1zF4Hv2bGZwLOYRBoMBgqui6oSusfh/YkOQ/gS08/GOHzwLuB76W5BbgVOClI1yxNdd+hs+RXJtkNXAOcF5VfQ3YALwtycEztnkJ8MYk/+HJds2Xd/+VJHVxRCJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQu/w84XGaJmTiLMgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# correlation matrix\n",
    "pd.DataFrame(df.corr()).to_csv(\"Correlation_Matrix.csv\")\n",
    "\n",
    "# bar graph to show to distribution of the label we are interested in\n",
    "y = df['SwellOneExit']\n",
    "hst = sns.countplot(x = y, data = df) # because the dataset is imbalanced, we will build models with both oversampling and undersampling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training test split\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X, Y, test_size = 0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17662\n",
       "0    17662\n",
       "Name: SwellOneExit, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## -- OVERSAMPLING -- ##\n",
    "\n",
    "# Oversampling the minority class \n",
    "df_ovsmpl = pd.concat([train_features, train_labels], axis=1)\n",
    "\n",
    "\n",
    "df_majority = df_ovsmpl[df_ovsmpl.SwellOneExit==0]\n",
    "df_minority = df_ovsmpl[df_ovsmpl.SwellOneExit==1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # oversampling with replacement\n",
    "                                 n_samples=len(df_majority),    # to match majority class size\n",
    "                                 random_state=123) # for reproducible results\n",
    " \n",
    "# combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled]) # final dataframe with oversampled minority class\n",
    " \n",
    "# display new class counts\n",
    "df_upsampled.SwellOneExit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling with oversampled dataframe\n",
    "\n",
    "upsmpl_Y = df_upsampled['SwellOneExit'] # label\n",
    "upsmpl_X = df_upsampled.drop('SwellOneExit', axis=1) # features\n",
    "\n",
    "# training test split of the oversampled dataframe\n",
    "upsmpl_train_features, upsmpl_test_features, upsmpl_train_labels, upsmpl_test_labels = train_test_split(upsmpl_X, upsmpl_Y, test_size = 0.2, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF_Umsampled_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.963905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.499887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[4433, 1], [165, 0]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RF_Umsampled_Score\n",
       "accuracy                       0.963905\n",
       "recall                                0\n",
       "precision                             0\n",
       "f1_score                              0\n",
       "roc_auc_score                  0.499887\n",
       "confusion_matrix  [[4433, 1], [165, 0]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Oversampled Modeling: Random Forest\n",
    "\n",
    "rf_upsampled = RandomForestClassifier(n_estimators = 1000, random_state=0, n_jobs=-1)\n",
    "\n",
    "# train model\n",
    "rf_upsampled_mdl = rf_upsampled.fit(upsmpl_train_features, upsmpl_train_labels)\n",
    "\n",
    "# test model\n",
    "rf_upsampled_pred = rf_upsampled_mdl.predict(test_features) # testing on the test features from the original dataframe\n",
    "\n",
    "\n",
    "# performance matrix\n",
    "rf_upsmpl_matrix = pd.DataFrame(data=[accuracy_score(test_labels, rf_upsampled_pred), recall_score(test_labels, rf_upsampled_pred), precision_score(test_labels, rf_upsampled_pred), f1_score(test_labels, rf_upsampled_pred), roc_auc_score(test_labels, rf_upsampled_pred), confusion_matrix(test_labels, rf_upsampled_pred)],\n",
    "                                index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\", \"confusion_matrix\"],\n",
    "                                columns=['RF_Umsampled_Score'])\n",
    "\n",
    "rf_upsmpl_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.683409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.490909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0557467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.100124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.590741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[3062, 1372], [84, 81]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 XGB_Score\n",
       "accuracy                          0.683409\n",
       "recall                            0.490909\n",
       "precision                        0.0557467\n",
       "f1_score                          0.100124\n",
       "roc_auc_score                     0.590741\n",
       "confusion_matrix  [[3062, 1372], [84, 81]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost\n",
    "\n",
    "ratio_neg_pos = (len(test_labels) - test_labels.sum()) / test_labels.sum() # ratio of majority to minority class\n",
    "xgb_mdl = xgb.XGBClassifier(scale_pos_weight = ratio_neg_pos).fit(train_features, train_labels) # xgboost adjusts for the imbalanced dataset\n",
    "\n",
    "xgb_mdl_pred = xgb_mdl.predict(test_features) # test model\n",
    "\n",
    "# performance matrix\n",
    "xgb_matrix = pd.DataFrame(data=[accuracy_score(test_labels, xgb_mdl_pred), recall_score(test_labels, xgb_mdl_pred), precision_score(test_labels, xgb_mdl_pred), f1_score(test_labels, xgb_mdl_pred), roc_auc_score(test_labels, xgb_mdl_pred), confusion_matrix(test_labels, xgb_mdl_pred)],\n",
    "                                index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\", \"confusion_matrix\"],\n",
    "                                columns=['XGB_Score'])\n",
    "\n",
    "xgb_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB_Upsampled_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.765384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.387879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0614203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.106048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.583655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[3456, 978], [101, 64]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       XGB_Upsampled_Score\n",
       "accuracy                          0.765384\n",
       "recall                            0.387879\n",
       "precision                        0.0614203\n",
       "f1_score                          0.106048\n",
       "roc_auc_score                     0.583655\n",
       "confusion_matrix  [[3456, 978], [101, 64]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost with Oversampled Dataframe\n",
    "\n",
    "# ratio_neg_pos = (len(test_labels) - test_labels.sum()) / test_labels.sum() # ratio of majority to minority class\n",
    "xgb_upsmpl_mdl = xgb.XGBClassifier().fit(upsmpl_train_features, upsmpl_train_labels)\n",
    "\n",
    "# test model\n",
    "xgb_upsmpl_mdl_pred = xgb_upsmpl_mdl.predict(test_features)\n",
    "\n",
    "# Performance Matrix\n",
    "xgb_upsmpl_matrix = pd.DataFrame(data=[accuracy_score(test_labels, xgb_upsmpl_mdl_pred), recall_score(test_labels, xgb_upsmpl_mdl_pred), precision_score(test_labels, xgb_upsmpl_mdl_pred), f1_score(test_labels, xgb_upsmpl_mdl_pred), roc_auc_score(test_labels, xgb_upsmpl_mdl_pred), confusion_matrix(test_labels, xgb_upsmpl_mdl_pred)],\n",
    "                                index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\", \"confusion_matrix\"],\n",
    "                                columns=['XGB_Upsampled_Score'])\n",
    "\n",
    "xgb_upsmpl_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR_Upsampled_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.636878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0534125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.0972973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.592867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[2839, 1595], [75, 90]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        LR_Upsampled_Score\n",
       "accuracy                          0.636878\n",
       "recall                            0.545455\n",
       "precision                        0.0534125\n",
       "f1_score                         0.0972973\n",
       "roc_auc_score                     0.592867\n",
       "confusion_matrix  [[2839, 1595], [75, 90]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Oversampled Modeling: Logistic Regression\n",
    "lr_upsampled = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# train model\n",
    "lr_upsampled_mdl = lr_upsampled.fit(upsmpl_train_features, upsmpl_train_labels)\n",
    "\n",
    "\n",
    "# test model\n",
    "lr_upsampled_pred = lr_upsampled_mdl.predict(test_features)\n",
    "\n",
    "# performance matrix\n",
    "lr_upsmpl_matrix = pd.DataFrame(data=[accuracy_score(test_labels, lr_upsampled_pred), recall_score(test_labels, lr_upsampled_pred), precision_score(test_labels, lr_upsampled_pred), f1_score(test_labels, lr_upsampled_pred), roc_auc_score(test_labels, lr_upsampled_pred), confusion_matrix(test_labels, lr_upsampled_pred)],\n",
    "                                index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\", \"confusion_matrix\"],\n",
    "                                columns=['LR_Upsampled_Score'])\n",
    "\n",
    "lr_upsmpl_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.636878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.053412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.592867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Score\n",
       "accuracy       0.636878\n",
       "recall         0.545455\n",
       "precision      0.053412\n",
       "roc_auc_score  0.592867"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression threshold\n",
    "\n",
    "threshold = .5 # change the threshold here (default is 0.5)\n",
    "\n",
    "preds = np.where(lr_upsampled_mdl.predict_proba(test_features)[:,1] > threshold, 1, 0) # classifies test features above the threshold as class 1 (exit group)\n",
    "\n",
    "pd.DataFrame(data=[accuracy_score(test_labels, preds), recall_score(test_labels, preds),\n",
    "                   precision_score(test_labels, preds), roc_auc_score(test_labels, preds)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"roc_auc_score\"], columns=['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SecondYearsInSchoolNoMissing -1.4246497509663592\n",
      "CMsInSchoolNoMissing 1.3858633947570151\n",
      "FirstYearsInSchoolNoMissing -1.3645018716592934\n",
      "RentPropNoMissing 1.245738363213029\n",
      "Grade_ECE 0.8584735204751934\n",
      "Grade_Unknown -0.7359877703037103\n",
      "PredModelScoreNoMissing -0.626686371486903\n",
      "GenderMale 0.47796077739560344\n",
      "Eth_Native 0.4580844116063389\n",
      "GenderFemale 0.4058830995902985\n",
      "School_Charter 0.3697832049111486\n",
      "Urbanicity_Urban 0.3490365654803064\n",
      "Eth_Black -0.34693832212989345\n",
      "COL_High 0.33825065025942197\n",
      "LGB_NoProtect 0.30792363399861283\n",
      "Urbanicity_Rural -0.29929457826567885\n",
      "AttendLIC_HS_Unknown 0.26052163783661036\n",
      "LGB_StateProtect -0.2161343453957831\n",
      "CalcUndergrad 0.20906472486064648\n",
      "Eth_AsianAmPacIsl 0.2074555314593879\n",
      "School_Other -0.1930542806222567\n",
      "Grade_UPPERELEM 0.18533102341829188\n",
      "TeacherPP_No 0.17977317209231494\n",
      "COL_Medium -0.16650358231380716\n",
      "HadFamRespNull 0.1541445505490504\n",
      "VarsitySport_No_Or_Unknown 0.14217119060043412\n",
      "CLI6NoMissing -0.14051854708613493\n",
      "Title1Yes 0.1399721416328767\n",
      "CalcUnknown -0.13634710935229272\n",
      "FinalAchievementNoMissing 0.13412780637883526\n",
      "PellGrantNoOrMissing 0.1326112405204035\n",
      "GrewUpLIC_Yes 0.1325866885509698\n",
      "CalcGradStudent 0.12873841823133175\n",
      "Urbanicity_Both 0.12397855830315968\n",
      "LIC_Served_Yes 0.1137074078430305\n",
      "Eth_MultiEthMultiRacial -0.11035493201181974\n",
      "K12TeachNo 0.10208827592142075\n",
      "MajorTeaching_Mismatch 0.09939312556476912\n",
      "DeferralNotRequested 0.09918935971936953\n",
      "CSI12NoMissing -0.09191498613947922\n",
      "Grade_HIGH -0.09140543683277695\n",
      "MajorOffered_Mismatch 0.08931661434610275\n",
      "Grade_LOWELEM -0.08481976328314532\n",
      "MajorOffered_Match 0.08440393116800451\n",
      "Region_Large 0.08410258694849966\n",
      "AttendLIC_HS_Yes -0.08357057415670191\n",
      "Region_Medium 0.08284483576652561\n",
      "LGB_LocalProtect 0.08193125691468475\n",
      "DeferralRequested 0.07453118578442029\n",
      "MajorTeaching_Match 0.07432741994528601\n",
      "Eth_OtherOrUnknown -0.07088889077756295\n",
      "CommAndPresNoMissing -0.06855073420025239\n",
      "CSI5NoMissing -0.06829163419236974\n",
      "K12TeachNull 0.06582865434177311\n",
      "PerseveranceNoMissing -0.061461727321021856\n",
      "LIC_Served_No_Or_Unknown 0.06001313766966632\n",
      "SchoolSelectivityNoMissing -0.058899982035441945\n",
      "HadFamRespYes 0.05223393696838168\n",
      "YearsPartnerPartnerNoMissing 0.05098614488156111\n",
      "Grade_MIDDLE 0.042128972043749116\n",
      "GrewUpLIC_No_Or_Unknown 0.04113385696292433\n",
      "PellGrantYes 0.04110930499269605\n",
      "AgeAtFDOSNoMissing 0.040736714255507143\n",
      "CSI3NoMissing -0.03726323372620342\n",
      "Eth_Latinx 0.037104592681973345\n",
      "Title1No 0.0337484038823921\n",
      "HadFamRespNo -0.03265794200434645\n",
      "RelationshipBuildingNoMissing -0.03255691106582886\n",
      "VarsitySport_Yes 0.031549354909037604\n",
      "RegPrefLevNoMissing 0.02452069408538317\n",
      "YearsSchoolPartnerNoMissing -0.021476303229813712\n",
      "FRPLNoMissing -0.01973191203004657\n",
      "FitNoMissing 0.018231139884181475\n",
      "CalcProfessional -0.016925484292738047\n",
      "OtherCMsSameCoachNoMissing -0.014288069635729574\n",
      "CSI6NoMissing -0.014028604358881275\n",
      "CumuGPANoMissing -0.013612627214362308\n",
      "CMProspectRatingNoMissing 0.013553317000447831\n",
      "CalcJunior -0.010810003931546895\n",
      "YearsAsCoach 0.010441842199536288\n",
      "CLI8NoMissing -0.010337305015127706\n",
      "Region_Small 0.006773122800454493\n",
      "TeacherPP_Yes -0.006052626575806393\n",
      "K12TeachYes 0.0058036152514173685\n",
      "DaysTSubmitNoMissing -0.0037695687992300125\n",
      "AttendLIC_HS_No -0.0032305181625954136\n",
      "School_Public -0.0030083787760443333\n",
      "OtherCMsPrevCoachNoMissing 0.002603058143159217\n",
      "COL_Low 0.0019734775701986803\n",
      "AvgRentNoMissing -0.0010330551088555081\n",
      "CorpsSizeNoMissing -0.0007721674264201385\n",
      "Eth_White -0.000741845310181927\n",
      "AvgFirstMonthSalNoMissing 0.0001133798682131445\n",
      "CertProgramCostNoMissing 2.856105687511381e-06\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Umsampled Model Feature Importance\n",
    "\n",
    "importance = lr_upsampled_mdl.coef_[0]\n",
    "feature_dict = {}\n",
    "for v, n in zip(importance, req_vars[1:]): #zipping the feature importance by the magnitude of their coefficients\n",
    "    feature_dict[n] = v\n",
    "for k, v in sorted(feature_dict.items(), key=lambda item: abs(item[1]), reverse=True):\n",
    "    print(k, v)\n",
    "\n",
    "# exporting the dictionary to CSV file\n",
    "pd.DataFrame.from_dict(feature_dict, orient='index').to_csv('Logistic_Regression_Feature_Importance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.645038\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prastha/opt/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/prastha/opt/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:1354: RuntimeWarning: invalid value encountered in sqrt\n",
      "  bse_ = np.sqrt(np.diag(self.cov_params()))\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Summary Table (to get statistical significance of all features) \n",
    "\n",
    "# training the model\n",
    "\n",
    "lr2 = sm.add_constant(upsmpl_train_features) # add constant to the regression line\n",
    "lr2 = sm.Logit(upsmpl_train_labels, upsmpl_train_features).fit(cov_type='HC1') # account for heteroskedasticity\n",
    "lr2_summary = lr2.summary() # summary table of the regression results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting the summary table to CSV\n",
    "lr2_as_html = lr2_summary.tables[1].as_html() # convert the table into an HTML file\n",
    "\n",
    "lr2_pd = pd.read_html(lr2_as_html, header=0, index_col=0)[0] # HTML file as pandas dataframe\n",
    "\n",
    "lr2_pd = lr2_pd.sort_values(by = ['P>|z|']) # sort the dataframe in increasing order of p-values\n",
    "                                            # meaning most statistically significant at first\n",
    "\n",
    "lr2_pd.to_csv(\"Logistic_Regression_Table.csv\") #export the df to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    731\n",
       "0    731\n",
       "Name: SwellOneExit, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## -- UNDERSAMPLING -- ##\n",
    "\n",
    "df_undsmpl = pd.concat([train_features, train_labels], axis=1)\n",
    "\n",
    "\n",
    "df_undsmpl_majority = df_undsmpl[df_undsmpl.SwellOneExit==0]\n",
    "df_undsmpl_minority = df_undsmpl[df_undsmpl.SwellOneExit==1]\n",
    "\n",
    "# undersample majority class\n",
    "df_majority_undsampled = resample(df_undsmpl_majority, \n",
    "                                 replace=False,     # sample without replacement\n",
    "                                 n_samples=len(df_undsmpl_minority),    # to match minority class\n",
    "                                 random_state=123) # for reproducible results\n",
    " \n",
    "# combine minority class with undersampled majority class\n",
    "df_undsampled = pd.concat([df_majority_undsampled, df_undsmpl_minority]) # undersampled dataframe\n",
    " \n",
    "# display new class counts\n",
    "df_undsampled.SwellOneExit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training test split for undersampled dataframe\n",
    "undsmpl_Y = df_undsampled['SwellOneExit'] # labels\n",
    "undsmpl_X = df_undsampled.drop('SwellOneExit', axis=1) # features\n",
    "\n",
    "undsmpl_train_features, undsmpl_test_features, undsmpl_train_labels, undsmpl_test_labels = train_test_split(undsmpl_X, undsmpl_Y, test_size = 0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB_Downsampled_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.626441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0519331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.0948367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.587454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[2791, 1643], [75, 90]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     XGB_Downsampled_Score\n",
       "accuracy                          0.626441\n",
       "recall                            0.545455\n",
       "precision                        0.0519331\n",
       "f1_score                         0.0948367\n",
       "roc_auc_score                     0.587454\n",
       "confusion_matrix  [[2791, 1643], [75, 90]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undersampled Modeling: XGBoost\n",
    "\n",
    "xgb_undsmpl_model = xgb.XGBClassifier()\n",
    "xgb_undsmpl_model.fit(undsmpl_train_features, undsmpl_train_labels) # training the model\n",
    "\n",
    "xgb_undsmpl_model_pred = xgb_undsmpl_model.predict(test_features) # testing the model\n",
    "\n",
    "# performance matrix\n",
    "xgb_dwnsmpl_matrix = pd.DataFrame(data=[accuracy_score(test_labels, xgb_undsmpl_model_pred), recall_score(test_labels, xgb_undsmpl_model_pred), precision_score(test_labels, xgb_undsmpl_model_pred), f1_score(test_labels, xgb_undsmpl_model_pred), roc_auc_score(test_labels, xgb_undsmpl_model_pred), confusion_matrix(test_labels, xgb_undsmpl_model_pred)],\n",
    "                                index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\", \"confusion_matrix\"],\n",
    "                                columns=['XGB_Downsampled_Score'])\n",
    "\n",
    "xgb_dwnsmpl_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF_Downsampled_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.61035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.581818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0527763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.0967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.596615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[2711, 1723], [69, 96]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      RF_Downsampled_Score\n",
       "accuracy                           0.61035\n",
       "recall                            0.581818\n",
       "precision                        0.0527763\n",
       "f1_score                         0.0967742\n",
       "roc_auc_score                     0.596615\n",
       "confusion_matrix  [[2711, 1723], [69, 96]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undersampled Modeling: Random Forest\n",
    "\n",
    "rf_downsampled = RandomForestClassifier(n_estimators = 1000, random_state=0, n_jobs=-1)\n",
    "\n",
    "# train model\n",
    "rf_downsampled_mdl = rf_downsampled.fit(undsmpl_train_features, undsmpl_train_labels)\n",
    "\n",
    "# test model\n",
    "rf_downsampled_pred = rf_downsampled_mdl.predict(test_features)\n",
    "\n",
    "rf_dwnsmpl_matrix = pd.DataFrame(data=[accuracy_score(test_labels, rf_downsampled_pred), recall_score(test_labels, rf_downsampled_pred), precision_score(test_labels, rf_downsampled_pred), f1_score(test_labels, rf_downsampled_pred), roc_auc_score(test_labels, rf_downsampled_pred), confusion_matrix(test_labels, rf_downsampled_pred)],\n",
    "                                index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\", \"confusion_matrix\"],\n",
    "                                columns=['RF_Downsampled_Score'])\n",
    "\n",
    "rf_dwnsmpl_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance for RF Undersampling \n",
    "\n",
    "rf_importance = rf_downsampled_mdl.feature_importances_\n",
    "    \n",
    "rf_feature_dict = {}\n",
    "for v, n in zip(rf_importance, req_vars[1:]):\n",
    "    rf_feature_dict[n] = v\n",
    "\n",
    "rf_importance_df = pd.DataFrame.from_dict(rf_feature_dict, orient='index') # create a pandas df from the dictionary\n",
    "\n",
    "rf_importance_df.columns = ['Feature Importance']\n",
    "\n",
    "rf_importance_df = rf_importance_df.sort_values(by = ['Feature Importance'], ascending=False) # sort the df by feature importance in descending order\n",
    "\n",
    "rf_importance_df.to_csv(\"RF_Undersampled_Feature_Importance.csv\") # export the df to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR_Downsampled_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.599913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.593939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0523784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.0962672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.597037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[2661, 1773], [67, 98]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      LR_Downsampled_Score\n",
       "accuracy                          0.599913\n",
       "recall                            0.593939\n",
       "precision                        0.0523784\n",
       "f1_score                         0.0962672\n",
       "roc_auc_score                     0.597037\n",
       "confusion_matrix  [[2661, 1773], [67, 98]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undersampled Modeling: Logistic Regression\n",
    "\n",
    "# logistic regression\n",
    "lr_undsampled = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# train model\n",
    "lr_undsampled_mdl = lr_undsampled.fit(undsmpl_train_features, undsmpl_train_labels)\n",
    "\n",
    "# test model\n",
    "lr_undsampled_pred = lr_undsampled_mdl.predict(test_features)\n",
    "\n",
    "lr_dwnsmpl_matrix = pd.DataFrame(data=[accuracy_score(test_labels, lr_undsampled_pred), recall_score(test_labels, lr_undsampled_pred), precision_score(test_labels, lr_undsampled_pred), f1_score(test_labels, lr_undsampled_pred), roc_auc_score(test_labels, lr_undsampled_pred), confusion_matrix(test_labels, lr_undsampled_pred)],\n",
    "                                index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\", \"confusion_matrix\"],\n",
    "                                columns=['LR_Downsampled_Score'])\n",
    "\n",
    "lr_dwnsmpl_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.616775\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prastha/opt/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/prastha/opt/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:1354: RuntimeWarning: invalid value encountered in sqrt\n",
      "  bse_ = np.sqrt(np.diag(self.cov_params()))\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Summary Stats (for Undersampling)\n",
    "\n",
    "# training the model\n",
    "\n",
    "lr2_undsmpl_mdl = sm.add_constant(undsmpl_train_features)\n",
    "lr2_undsmpl_mdl = sm.Logit(undsmpl_train_labels, undsmpl_train_features).fit(cov_type='HC1')\n",
    "lr2_undsmpl_mdl_summary = lr2_undsmpl_mdl.summary()\n",
    "\n",
    "# exporting the model to CSV\n",
    "lr2_undsmpl_mdl_as_html = lr2_undsmpl_mdl_summary.tables[1].as_html()\n",
    "lr2_undsmpl_mdl_pd = pd.read_html(lr2_undsmpl_mdl_as_html, header=0, index_col=0)[0]\n",
    "\n",
    "lr2_undsmpl_mdl_pd = lr2_undsmpl_mdl_pd.sort_values(by = ['P>|z|'])\n",
    "\n",
    "# lr2_pd.to_csv(\"Logistic_Regression_Table.csv\")\n",
    "\n",
    "lr2_undsmpl_mdl_pd.to_csv(\"Logistic_Regression_Undersampled_Table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Matrix of All Matrices in a spreadsheet\n",
    "\n",
    "mdl_matrices = [xgb_matrix, rf_upsmpl_matrix, lr_upsmpl_matrix, xgb_upsmpl_matrix, rf_dwnsmpl_matrix, lr_dwnsmpl_matrix, xgb_dwnsmpl_matrix]\n",
    "\n",
    "pd.concat(mdl_matrices, axis=1).to_csv(\"Performance_Matrix_of_All_Models.csv\") # concatinating all dfs and exporting to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">LR_Upsampled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.644705</td>\n",
       "      <td>0.64514</td>\n",
       "      <td>0.655285</td>\n",
       "      <td>0.639408</td>\n",
       "      <td>0.649413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0550459</td>\n",
       "      <td>0.059466</td>\n",
       "      <td>0.053934</td>\n",
       "      <td>0.059034</td>\n",
       "      <td>0.0557967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.502793</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.47486</td>\n",
       "      <td>0.553073</td>\n",
       "      <td>0.502793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.0992282</td>\n",
       "      <td>0.107221</td>\n",
       "      <td>0.0968661</td>\n",
       "      <td>0.106681</td>\n",
       "      <td>0.100446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[2875, 1545], [89, 90]]</td>\n",
       "      <td>[[2869, 1550], [82, 98]]</td>\n",
       "      <td>[[2928, 1491], [94, 85]]</td>\n",
       "      <td>[[2841, 1578], [80, 99]]</td>\n",
       "      <td>[[2896, 1523], [89, 90]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              LR_Upsampled                            \\\n",
       "                                         0                         1   \n",
       "accuracy                          0.644705                   0.64514   \n",
       "precision                        0.0550459                  0.059466   \n",
       "recall                            0.502793                  0.544444   \n",
       "f1                               0.0992282                  0.107221   \n",
       "confusion_matrix  [[2875, 1545], [89, 90]]  [[2869, 1550], [82, 98]]   \n",
       "\n",
       "                                                                      \\\n",
       "                                         2                         3   \n",
       "accuracy                          0.655285                  0.639408   \n",
       "precision                         0.053934                  0.059034   \n",
       "recall                             0.47486                  0.553073   \n",
       "f1                               0.0968661                  0.106681   \n",
       "confusion_matrix  [[2928, 1491], [94, 85]]  [[2841, 1578], [80, 99]]   \n",
       "\n",
       "                                            \n",
       "                                         4  \n",
       "accuracy                          0.649413  \n",
       "precision                        0.0557967  \n",
       "recall                            0.502793  \n",
       "f1                                0.100446  \n",
       "confusion_matrix  [[2896, 1523], [89, 90]]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validation with Logistic Regression with Upsampled Dataframe\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "X = df.drop('SwellOneExit',axis=1)\n",
    "Y = df['SwellOneExit']\n",
    "\n",
    "lr_upsmpl_cv_acc_score_list = []\n",
    "lr_upsmpl_cv_recall_list = []\n",
    "lr_upsmpl_cv_precision_list = []\n",
    "lr_upsmpl_cv_f1_list = []\n",
    "lr_upsmpl_cv_confusion_list = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    train_features, test_features = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    train_labels, test_labels = Y[train_index], Y[test_index]\n",
    "    \n",
    "    df_ovsmpl = pd.concat([train_features, train_labels], axis=1)\n",
    "    df_majority = df_ovsmpl[df_ovsmpl.SwellOneExit==0]\n",
    "    df_minority = df_ovsmpl[df_ovsmpl.SwellOneExit==1]\n",
    "    \n",
    "    # Upsample minority class\n",
    "    df_minority_upsampled = resample(df_minority, \n",
    "                                     replace=True,     # sample with replacement\n",
    "                                     n_samples=len(df_majority),    # to match majority class\n",
    "                                     random_state=123) # reproducible results\n",
    "    # Combine majority class with upsampled minority class\n",
    "    df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "    upsmpl_Y = df_upsampled['SwellOneExit']\n",
    "    upsmpl_X = df_upsampled.drop('SwellOneExit', axis=1)\n",
    "\n",
    "\n",
    "    lr_upsampled = LogisticRegression(solver='liblinear')\n",
    "\n",
    "    # train model\n",
    "    lr_upsampled_mdl = lr_upsampled.fit(upsmpl_X, upsmpl_Y)\n",
    "    \n",
    "    # test model\n",
    "    lr_upsampled_pred = lr_upsampled_mdl.predict(test_features)\n",
    "    \n",
    "    # performance matrix\n",
    "    lr_upsmpl_cv_acc_score_list.append(accuracy_score(test_labels, lr_upsampled_pred))\n",
    "    lr_upsmpl_cv_precision_list.append(precision_score(test_labels, lr_upsampled_pred))\n",
    "    lr_upsmpl_cv_recall_list.append(recall_score(test_labels, lr_upsampled_pred))\n",
    "    lr_upsmpl_cv_f1_list.append(f1_score(test_labels, lr_upsampled_pred))\n",
    "    lr_upsmpl_cv_confusion_list.append(confusion_matrix(test_labels, lr_upsampled_pred))\n",
    "\n",
    "    lr_upsmpl_cv = pd.DataFrame(data=[lr_upsmpl_cv_acc_score_list, lr_upsmpl_cv_precision_list, lr_upsmpl_cv_recall_list, lr_upsmpl_cv_f1_list, lr_upsmpl_cv_confusion_list], index=['accuracy', 'precision','recall', 'f1', 'confusion_matrix'])\n",
    "\n",
    "lr_upsmpl_cv.columns = pd.MultiIndex.from_tuples(zip(['LR_Upsampled', 'LR_Upsampled', 'LR_Upsampled', 'LR_Upsampled', 'LR_Upsampled'], lr_upsmpl_cv.columns))\n",
    "\n",
    "lr_upsmpl_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prastha/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/prastha/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/prastha/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/prastha/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">LR_Downsampled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.644705</td>\n",
       "      <td>0.64514</td>\n",
       "      <td>0.655285</td>\n",
       "      <td>0.639408</td>\n",
       "      <td>0.649413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0550459</td>\n",
       "      <td>0.059466</td>\n",
       "      <td>0.053934</td>\n",
       "      <td>0.059034</td>\n",
       "      <td>0.0557967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.502793</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.47486</td>\n",
       "      <td>0.553073</td>\n",
       "      <td>0.502793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.0992282</td>\n",
       "      <td>0.107221</td>\n",
       "      <td>0.0968661</td>\n",
       "      <td>0.106681</td>\n",
       "      <td>0.100446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[2875, 1545], [89, 90]]</td>\n",
       "      <td>[[2869, 1550], [82, 98]]</td>\n",
       "      <td>[[2928, 1491], [94, 85]]</td>\n",
       "      <td>[[2841, 1578], [80, 99]]</td>\n",
       "      <td>[[2896, 1523], [89, 90]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            LR_Downsampled                            \\\n",
       "                                         0                         1   \n",
       "accuracy                          0.644705                   0.64514   \n",
       "precision                        0.0550459                  0.059466   \n",
       "recall                            0.502793                  0.544444   \n",
       "f1                               0.0992282                  0.107221   \n",
       "confusion_matrix  [[2875, 1545], [89, 90]]  [[2869, 1550], [82, 98]]   \n",
       "\n",
       "                                                                      \\\n",
       "                                         2                         3   \n",
       "accuracy                          0.655285                  0.639408   \n",
       "precision                         0.053934                  0.059034   \n",
       "recall                             0.47486                  0.553073   \n",
       "f1                               0.0968661                  0.106681   \n",
       "confusion_matrix  [[2928, 1491], [94, 85]]  [[2841, 1578], [80, 99]]   \n",
       "\n",
       "                                            \n",
       "                                         4  \n",
       "accuracy                          0.649413  \n",
       "precision                        0.0557967  \n",
       "recall                            0.502793  \n",
       "f1                                0.100446  \n",
       "confusion_matrix  [[2896, 1523], [89, 90]]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validation with Logistic Regression with Downsampled Dataframe\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "X = df.drop('SwellOneExit',axis=1)\n",
    "Y = df['SwellOneExit']\n",
    "\n",
    "lr_dwnsmpl_cv_acc_score_list = []\n",
    "lr_dwnsmpl_cv_recall_list = []\n",
    "lr_dwnsmpl_cv_precision_list = []\n",
    "lr_dwnsmpl_cv_f1_list = []\n",
    "lr_dwnsmpl_cv_confusion_list = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    train_features, test_features = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    train_labels, test_labels = Y[train_index], Y[test_index]\n",
    "    \n",
    "    df_downsampled = pd.concat([train_features, train_labels], axis=1)\n",
    "    df_majority = df_downsampled[df_downsampled.SwellOneExit==0]\n",
    "    df_minority = df_downsampled[df_downsampled.SwellOneExit==1]\n",
    "    \n",
    "    # Upsample minority class\n",
    "    df_majority_downsampled = resample(df_majority, \n",
    "                                     replace=False,     # sample without replacement\n",
    "                                     n_samples=len(df_minority),    # to match minority class\n",
    "                                     random_state=123) # for reproducible results\n",
    "    \n",
    "    # Combine majority class with downsampled majority class\n",
    "    df_upsampled = pd.concat([df_minority, df_majority_downsampled])\n",
    "    dwnsmpl_Y = df_downsampled['SwellOneExit']\n",
    "    dwnsmpl_X = df_downsampled.drop('SwellOneExit', axis=1)\n",
    "\n",
    "\n",
    "    lr_downsampled = LogisticRegression(solver='liblinear')\n",
    "\n",
    "    # train model\n",
    "    lr_downsampled_mdl = lr_downsampled.fit(dwnsmpl_X, dwnsmpl_Y)\n",
    "    \n",
    "    # test model\n",
    "    lr_downsampled_pred = lr_downsampled_mdl.predict(test_features)\n",
    "    \n",
    "    # performance matrix\n",
    "    lr_dwnsmpl_cv_acc_score_list.append(accuracy_score(test_labels, lr_downsampled_pred))\n",
    "    lr_dwnsmpl_cv_precision_list.append(precision_score(test_labels, lr_downsampled_pred))\n",
    "    lr_dwnsmpl_cv_recall_list.append(recall_score(test_labels, lr_downsampled_pred))\n",
    "    lr_dwnsmpl_cv_f1_list.append(f1_score(test_labels, lr_downsampled_pred))\n",
    "    lr_dwnsmpl_cv_confusion_list.append(confusion_matrix(test_labels, lr_downsampled_pred))\n",
    "\n",
    "    lr_dwnsmpl_cv = pd.DataFrame(data=[lr_upsmpl_cv_acc_score_list, lr_upsmpl_cv_precision_list, lr_upsmpl_cv_recall_list, lr_upsmpl_cv_f1_list, lr_upsmpl_cv_confusion_list], index=['accuracy', 'precision','recall', 'f1', 'confusion_matrix'])\n",
    "\n",
    "lr_dwnsmpl_cv.columns = pd.MultiIndex.from_tuples(zip(['LR_Downsampled', 'LR_Downsampled', 'LR_Downsampled', 'LR_Downsampled', 'LR_Downsampled'], lr_dwnsmpl_cv.columns))\n",
    "\n",
    "lr_dwnsmpl_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">RF_Upsampled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.960861</td>\n",
       "      <td>0.960644</td>\n",
       "      <td>0.961288</td>\n",
       "      <td>0.961288</td>\n",
       "      <td>0.961288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00558659</td>\n",
       "      <td>0.00558659</td>\n",
       "      <td>0.00558659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0111111</td>\n",
       "      <td>0.0111111</td>\n",
       "      <td>0.0111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[4419, 1], [179, 0]]</td>\n",
       "      <td>[[4418, 1], [180, 0]]</td>\n",
       "      <td>[[4419, 0], [178, 1]]</td>\n",
       "      <td>[[4419, 0], [178, 1]]</td>\n",
       "      <td>[[4419, 0], [178, 1]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           RF_Upsampled                         \\\n",
       "                                      0                      1   \n",
       "accuracy                       0.960861               0.960644   \n",
       "precision                             0                      0   \n",
       "recall                                0                      0   \n",
       "f1                                    0                      0   \n",
       "confusion_matrix  [[4419, 1], [179, 0]]  [[4418, 1], [180, 0]]   \n",
       "\n",
       "                                                                \\\n",
       "                                      2                      3   \n",
       "accuracy                       0.961288               0.961288   \n",
       "precision                             1                      1   \n",
       "recall                       0.00558659             0.00558659   \n",
       "f1                            0.0111111              0.0111111   \n",
       "confusion_matrix  [[4419, 0], [178, 1]]  [[4419, 0], [178, 1]]   \n",
       "\n",
       "                                         \n",
       "                                      4  \n",
       "accuracy                       0.961288  \n",
       "precision                             1  \n",
       "recall                       0.00558659  \n",
       "f1                            0.0111111  \n",
       "confusion_matrix  [[4419, 0], [178, 1]]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validation with Random Forest with Upsampled Dataframe\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "X = df.drop('SwellOneExit',axis=1)\n",
    "Y = df['SwellOneExit']\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X, Y, test_size = 0.2, random_state=123)\n",
    "\n",
    "rf_upsmpl_cv_acc_score_list = []\n",
    "rf_upsmpl_cv_recall_list = []\n",
    "rf_upsmpl_cv_precision_list = []\n",
    "rf_upsmpl_cv_f1_list = []\n",
    "rf_upsmpl_cv_confusion_list = []\n",
    "\n",
    "for rf_train_index, rf_test_index in skf.split(X, Y):\n",
    "    rf_train_features, rf_test_features = X.iloc[rf_train_index, :], X.iloc[rf_test_index, :]\n",
    "    rf_train_labels, rf_test_labels = Y[rf_train_index], Y[rf_test_index]\n",
    "    \n",
    "    rf_df_ovsmpl = pd.concat([rf_train_features, rf_train_labels], axis=1)\n",
    "    rf_df_majority = rf_df_ovsmpl[rf_df_ovsmpl.SwellOneExit==0]\n",
    "    rf_df_minority = rf_df_ovsmpl[rf_df_ovsmpl.SwellOneExit==1]\n",
    "    \n",
    "    # Upsample minority class\n",
    "    rf_df_minority_upsampled = resample(rf_df_minority, \n",
    "                                     replace=True,     # sample with replacement\n",
    "                                     n_samples=len(df_majority),    # to match majority class\n",
    "                                     random_state=123) # reproducible results\n",
    "    # Combine majority class with upsampled minority class\n",
    "    rf_df_upsampled = pd.concat([rf_df_majority, rf_df_minority_upsampled])\n",
    "    rf_upsmpl_Y = rf_df_upsampled['SwellOneExit']\n",
    "    rf_upsmpl_X = rf_df_upsampled.drop('SwellOneExit', axis=1)\n",
    "\n",
    "\n",
    "    \n",
    "    rf_cv_upsampled = RandomForestClassifier(n_estimators = 1000, random_state=0, n_jobs=-1)\n",
    "\n",
    "    # train model\n",
    "    rf_cv_upsampled_mdl = rf_cv_upsampled.fit(rf_upsmpl_X, rf_upsmpl_Y)\n",
    "\n",
    "    # test model\n",
    "    rf_cv_upsampled_pred = rf_cv_upsampled_mdl.predict(rf_test_features) # testing on the test features from the original dataframe\n",
    "\n",
    "    rf_upsmpl_cv_acc_score_list.append(accuracy_score(rf_test_labels, rf_cv_upsampled_pred))\n",
    "    rf_upsmpl_cv_precision_list.append(precision_score(rf_test_labels, rf_cv_upsampled_pred))\n",
    "    rf_upsmpl_cv_recall_list.append(recall_score(rf_test_labels, rf_cv_upsampled_pred))\n",
    "    rf_upsmpl_cv_f1_list.append(f1_score(rf_test_labels, rf_cv_upsampled_pred))\n",
    "    rf_upsmpl_cv_confusion_list.append(confusion_matrix(rf_test_labels, rf_cv_upsampled_pred))\n",
    "\n",
    "    rf_upsmpl_cv = pd.DataFrame(data=[rf_upsmpl_cv_acc_score_list, rf_upsmpl_cv_precision_list, rf_upsmpl_cv_recall_list, rf_upsmpl_cv_f1_list, rf_upsmpl_cv_confusion_list], index=['accuracy', 'precision','recall', 'f1', 'confusion_matrix'])\n",
    "\n",
    "rf_upsmpl_cv.columns = pd.MultiIndex.from_tuples(zip(['RF_Upsampled', 'RF_Upsampled', 'RF_Upsampled', 'RF_Upsampled', 'RF_Upsampled'], rf_upsmpl_cv.columns))\n",
    "\n",
    "rf_upsmpl_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">RF_Downsampled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.632529</td>\n",
       "      <td>0.620352</td>\n",
       "      <td>0.616355</td>\n",
       "      <td>0.607438</td>\n",
       "      <td>0.602001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0526939</td>\n",
       "      <td>0.0510321</td>\n",
       "      <td>0.054525</td>\n",
       "      <td>0.0552516</td>\n",
       "      <td>0.0602025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.497207</td>\n",
       "      <td>0.494444</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>0.564246</td>\n",
       "      <td>0.631285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.0952891</td>\n",
       "      <td>0.0925156</td>\n",
       "      <td>0.0990807</td>\n",
       "      <td>0.100648</td>\n",
       "      <td>0.109922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[2820, 1600], [90, 89]]</td>\n",
       "      <td>[[2764, 1655], [91, 89]]</td>\n",
       "      <td>[[2737, 1682], [82, 97]]</td>\n",
       "      <td>[[2692, 1727], [78, 101]]</td>\n",
       "      <td>[[2655, 1764], [66, 113]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            RF_Downsampled                            \\\n",
       "                                         0                         1   \n",
       "accuracy                          0.632529                  0.620352   \n",
       "precision                        0.0526939                 0.0510321   \n",
       "recall                            0.497207                  0.494444   \n",
       "f1                               0.0952891                 0.0925156   \n",
       "confusion_matrix  [[2820, 1600], [90, 89]]  [[2764, 1655], [91, 89]]   \n",
       "\n",
       "                                                                       \\\n",
       "                                         2                          3   \n",
       "accuracy                          0.616355                   0.607438   \n",
       "precision                         0.054525                  0.0552516   \n",
       "recall                            0.541899                   0.564246   \n",
       "f1                               0.0990807                   0.100648   \n",
       "confusion_matrix  [[2737, 1682], [82, 97]]  [[2692, 1727], [78, 101]]   \n",
       "\n",
       "                                             \n",
       "                                          4  \n",
       "accuracy                           0.602001  \n",
       "precision                         0.0602025  \n",
       "recall                             0.631285  \n",
       "f1                                 0.109922  \n",
       "confusion_matrix  [[2655, 1764], [66, 113]]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validation with Random Forest with Downsampled Dataframe\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "X = df.drop('SwellOneExit',axis=1)\n",
    "Y = df['SwellOneExit']\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X, Y, test_size = 0.2, random_state=123)\n",
    "\n",
    "rf_dwnsmpl_cv_acc_score_list = []\n",
    "rf_dwnsmpl_cv_recall_list = []\n",
    "rf_dwnsmpl_cv_precision_list = []\n",
    "rf_dwnsmpl_cv_f1_list = []\n",
    "rf_dwnsmpl_cv_confusion_list = []\n",
    "\n",
    "for rf_train_index, rf_test_index in skf.split(X, Y):\n",
    "    rf_train_features, rf_test_features = X.iloc[rf_train_index, :], X.iloc[rf_test_index, :]\n",
    "    rf_train_labels, rf_test_labels = Y[rf_train_index], Y[rf_test_index]\n",
    "\n",
    "    rf_df_dwnsmpl = pd.concat([rf_train_features, rf_train_labels], axis=1)\n",
    "    rf_df_majority = rf_df_dwnsmpl[rf_df_dwnsmpl.SwellOneExit==0]\n",
    "    rf_df_minority = rf_df_dwnsmpl[rf_df_dwnsmpl.SwellOneExit==1]\n",
    "\n",
    "    # Upsample minority class\n",
    "    rf_df_majority_downsampled = resample(rf_df_majority,\n",
    "                                     replace=False,     # sample with replacement\n",
    "                                     n_samples=len(df_minority),    # to match majority class\n",
    "                                     random_state=123) # reproducible results\n",
    "    # Combine minority class with downsampled majority class\n",
    "    rf_df_downsampled = pd.concat([rf_df_minority, rf_df_majority_downsampled])\n",
    "    rf_dwnsmpl_Y = rf_df_downsampled['SwellOneExit']\n",
    "    rf_dwnsmpl_X = rf_df_downsampled.drop('SwellOneExit', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    rf_cv_downsampled = RandomForestClassifier(n_estimators = 1000, random_state=0, n_jobs=-1)\n",
    "\n",
    "    # train model\n",
    "    rf_cv_downsampled_mdl = rf_cv_downsampled.fit(rf_dwnsmpl_X, rf_dwnsmpl_Y)\n",
    "\n",
    "    # test model\n",
    "    rf_cv_downsampled_pred = rf_cv_downsampled_mdl.predict(rf_test_features) # testing on the test features from the original dataframe\n",
    "\n",
    "    rf_dwnsmpl_cv_acc_score_list.append(accuracy_score(rf_test_labels, rf_cv_downsampled_pred))\n",
    "    rf_dwnsmpl_cv_precision_list.append(precision_score(rf_test_labels, rf_cv_downsampled_pred))\n",
    "    rf_dwnsmpl_cv_recall_list.append(recall_score(rf_test_labels, rf_cv_downsampled_pred))\n",
    "    rf_dwnsmpl_cv_f1_list.append(f1_score(rf_test_labels, rf_cv_downsampled_pred))\n",
    "    rf_dwnsmpl_cv_confusion_list.append(confusion_matrix(rf_test_labels, rf_cv_downsampled_pred))\n",
    "\n",
    "    rf_dwnsmpl_cv = pd.DataFrame(data=[rf_dwnsmpl_cv_acc_score_list, rf_dwnsmpl_cv_precision_list, rf_dwnsmpl_cv_recall_list, rf_dwnsmpl_cv_f1_list, rf_dwnsmpl_cv_confusion_list], index=['accuracy', 'precision','recall', 'f1', 'confusion_matrix'])\n",
    "\n",
    "rf_dwnsmpl_cv.columns = pd.MultiIndex.from_tuples(zip(['RF_Downsampled', 'RF_Downsampled', 'RF_Downsampled', 'RF_Downsampled', 'RF_Downsampled'], rf_dwnsmpl_cv.columns))\n",
    "\n",
    "rf_dwnsmpl_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the cross validation results in a single dataframe\n",
    "\n",
    "cv_results = lr_upsmpl_cv.join(rf_upsmpl_cv.reindex(lr_upsmpl_cv.index, level=0)) # add LR and RF for upsampled results\n",
    "cv_results = cv_results.join(lr_dwnsmpl_cv.reindex(cv_results.index, level=0))\n",
    "cv_results = cv_results.join(rf_dwnsmpl_cv.reindex(cv_results.index, level=0))\n",
    "\n",
    "cv_results.to_csv('Cross_Validation_Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
