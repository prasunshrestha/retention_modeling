{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import xgboost as xgb\n",
    "from numpy import mean\n",
    "from sklearn import svm as svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score, roc_auc_score, accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "from sklearn.utils import resample\n",
    "random.seed(123)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Size: 22992\n",
      "# of predictors: 96\n"
     ]
    }
   ],
   "source": [
    "# dataset import\n",
    "df = pd.read_csv(\"Dataset_Scaled.csv\", low_memory=False)\n",
    "\n",
    "# dataset shape\n",
    "print(\"Sample Size:\", df.shape[0])\n",
    "print(\"# of predictors:\", df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required variables, features, and label\n",
    "\n",
    "req_vars = ['SwellOneExit', 'YearsAsCoach', 'DaysTSubmitNoMissing',\n",
    "       'FitNoMissing', 'RelationshipBuildingNoMissing',\n",
    "       'FinalAchievementNoMissing', 'CommAndPresNoMissing',\n",
    "       'PredModelScoreNoMissing', 'CMProspectRatingNoMissing',\n",
    "       'AgeAtFDOSNoMissing', 'SchoolSelectivityNoMissing',\n",
    "       'CumuGPANoMissing', 'PerseveranceNoMissing', 'FRPLNoMissing',\n",
    "       'YearsSchoolPartnerNoMissing', 'YearsPartnerPartnerNoMissing',\n",
    "       'FirstYearsInSchoolNoMissing', 'SecondYearsInSchoolNoMissing',\n",
    "       'CMsInSchoolNoMissing', 'CertProgramCostNoMissing',\n",
    "       'AvgFirstMonthSalNoMissing', 'RentPropNoMissing',\n",
    "       'AvgRentNoMissing', 'CorpsSizeNoMissing', 'RegPrefLevNoMissing',\n",
    "       'CSI6NoMissing', 'CSI5NoMissing', 'CSI3NoMissing',\n",
    "       'CSI12NoMissing', 'CLI8NoMissing', 'CLI6NoMissing',\n",
    "       'OtherCMsSameCoachNoMissing', 'OtherCMsPrevCoachNoMissing',\n",
    "       'K12TeachNo', 'K12TeachYes', 'K12TeachNull', 'HadFamRespNo',\n",
    "       'HadFamRespYes', 'HadFamRespNull', 'PellGrantNoOrMissing',\n",
    "       'PellGrantYes', 'GenderFemale', 'GenderMale', 'CalcGradStudent',\n",
    "       'CalcJunior', 'CalcProfessional', 'CalcUndergrad', 'CalcUnknown',\n",
    "       'AttendLIC_HS_No', 'AttendLIC_HS_Yes', 'AttendLIC_HS_Unknown',\n",
    "       'GrewUpLIC_No_Or_Unknown', 'GrewUpLIC_Yes',\n",
    "       'LIC_Served_No_Or_Unknown', 'LIC_Served_Yes', 'Eth_Black',\n",
    "       'Eth_Native', 'Eth_AsianAmPacIsl', 'Eth_Latinx',\n",
    "       'Eth_MultiEthMultiRacial', 'Eth_OtherOrUnknown', 'Eth_White',\n",
    "       'VarsitySport_No_Or_Unknown', 'VarsitySport_Yes',\n",
    "       'DeferralRequested', 'DeferralNotRequested', 'Title1No',\n",
    "       'Title1Yes', 'Grade_ECE', 'Grade_HIGH', 'Grade_LOWELEM',\n",
    "       'Grade_MIDDLE', 'Grade_UPPERELEM', 'Grade_Unknown',\n",
    "       'School_Charter', 'School_Public', 'School_Other', 'LGB_NoProtect',\n",
    "       'LGB_LocalProtect', 'LGB_StateProtect', 'TeacherPP_No',\n",
    "       'TeacherPP_Yes', 'Region_Large', 'Region_Medium', 'Region_Small',\n",
    "       'Urbanicity_Both', 'Urbanicity_Rural', 'Urbanicity_Urban',\n",
    "       'COL_High', 'COL_Low', 'COL_Medium', 'MajorTeaching_Match',\n",
    "       'MajorTeaching_Mismatch', 'MajorOffered_Match',\n",
    "       'MajorOffered_Mismatch']\n",
    "\n",
    "df = df[req_vars] # updating the dataframe with only required variables\n",
    "\n",
    "Y = df['SwellOneExit'] # label\n",
    "X = pd.DataFrame(df.drop(['SwellOneExit', 'FirstYearsInSchoolNoMissing', 'SecondYearsInSchoolNoMissing'], axis=1)) # dropping first years and second years because of multicollinearity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# correlation matrix\n",
    "pd.DataFrame(df.corr()).to_csv(\"Correlation_Matrix_Scaled_DF.csv\")\n",
    "\n",
    "# bar graph to show to distribution of the label we are interested in\n",
    "y = df['SwellOneExit']\n",
    "hst = sns.countplot(x = y, data = df) # because the dataset is imbalanced, we will build models with both oversampling and undersampling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training test split\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X, Y, test_size = 0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17662\n",
       "0    17662\n",
       "Name: SwellOneExit, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## -- OVERSAMPLING -- ##\n",
    "\n",
    "# Oversampling the minority class \n",
    "df_ovsmpl = pd.concat([train_features, train_labels], axis=1)\n",
    "\n",
    "\n",
    "df_majority = df_ovsmpl[df_ovsmpl.SwellOneExit==0]\n",
    "df_minority = df_ovsmpl[df_ovsmpl.SwellOneExit==1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # oversampling with replacement\n",
    "                                 n_samples=len(df_majority),    # to match majority class size\n",
    "                                 random_state=123) # for reproducible results\n",
    " \n",
    "# combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled]) # final dataframe with oversampled minority class\n",
    " \n",
    "# display new class counts\n",
    "df_upsampled.SwellOneExit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling with oversampled dataframe\n",
    "\n",
    "upsmpl_Y = df_upsampled['SwellOneExit'] # label\n",
    "upsmpl_X = df_upsampled.drop('SwellOneExit', axis=1) # features\n",
    "\n",
    "# training test split of the oversampled dataframe\n",
    "upsmpl_train_features, upsmpl_test_features, upsmpl_train_labels, upsmpl_test_labels = train_test_split(upsmpl_X, upsmpl_Y, test_size = 0.2, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF_Umsampled_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.963905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.499887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[4433, 1], [165, 0]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RF_Umsampled_Score\n",
       "accuracy                       0.963905\n",
       "recall                                0\n",
       "precision                             0\n",
       "f1_score                              0\n",
       "roc_auc_score                  0.499887\n",
       "confusion_matrix  [[4433, 1], [165, 0]]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Oversampled Modeling: Random Forest\n",
    "\n",
    "rf_upsampled = RandomForestClassifier(n_estimators = 1000, random_state=0, n_jobs=-1)\n",
    "\n",
    "# train model\n",
    "rf_upsampled_mdl = rf_upsampled.fit(upsmpl_train_features, upsmpl_train_labels)\n",
    "\n",
    "# test model\n",
    "rf_upsampled_pred = rf_upsampled_mdl.predict(test_features) # testing on the test features from the original dataframe\n",
    "\n",
    "\n",
    "# performance matrix\n",
    "rf_upsmpl_matrix = pd.DataFrame(data=[accuracy_score(test_labels, rf_upsampled_pred), recall_score(test_labels, rf_upsampled_pred), precision_score(test_labels, rf_upsampled_pred), f1_score(test_labels, rf_upsampled_pred), roc_auc_score(test_labels, rf_upsampled_pred), confusion_matrix(test_labels, rf_upsampled_pred)],\n",
    "                                index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\", \"confusion_matrix\"],\n",
    "                                columns=['RF_Umsampled_Score'])\n",
    "\n",
    "rf_upsmpl_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.680583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.460606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0521978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.0937693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.574687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[3054, 1380], [89, 76]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 XGB_Score\n",
       "accuracy                          0.680583\n",
       "recall                            0.460606\n",
       "precision                        0.0521978\n",
       "f1_score                         0.0937693\n",
       "roc_auc_score                     0.574687\n",
       "confusion_matrix  [[3054, 1380], [89, 76]]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost\n",
    "\n",
    "ratio_neg_pos = (len(test_labels) - test_labels.sum()) / test_labels.sum() # ratio of majority to minority class\n",
    "xgb_mdl = xgb.XGBClassifier(scale_pos_weight = ratio_neg_pos).fit(train_features, train_labels) # xgboost adjusts for the imbalanced dataset\n",
    "\n",
    "xgb_mdl_pred = xgb_mdl.predict(test_features) # test model\n",
    "\n",
    "# performance matrix\n",
    "xgb_matrix = pd.DataFrame(data=[accuracy_score(test_labels, xgb_mdl_pred), recall_score(test_labels, xgb_mdl_pred), precision_score(test_labels, xgb_mdl_pred), f1_score(test_labels, xgb_mdl_pred), roc_auc_score(test_labels, xgb_mdl_pred), confusion_matrix(test_labels, xgb_mdl_pred)],\n",
    "                                index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\", \"confusion_matrix\"],\n",
    "                                columns=['XGB_Score'])\n",
    "\n",
    "xgb_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB_Upsampled_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.757339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.436364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.114286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.602823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[3411, 1023], [93, 72]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       XGB_Upsampled_Score\n",
       "accuracy                          0.757339\n",
       "recall                            0.436364\n",
       "precision                        0.0657534\n",
       "f1_score                          0.114286\n",
       "roc_auc_score                     0.602823\n",
       "confusion_matrix  [[3411, 1023], [93, 72]]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost with Oversampled Dataframe\n",
    "\n",
    "# ratio_neg_pos = (len(test_labels) - test_labels.sum()) / test_labels.sum() # ratio of majority to minority class\n",
    "xgb_upsmpl_mdl = xgb.XGBClassifier().fit(upsmpl_train_features, upsmpl_train_labels)\n",
    "\n",
    "# test model\n",
    "xgb_upsmpl_mdl_pred = xgb_upsmpl_mdl.predict(test_features)\n",
    "\n",
    "# Performance Matrix\n",
    "xgb_upsmpl_matrix = pd.DataFrame(data=[accuracy_score(test_labels, xgb_upsmpl_mdl_pred), recall_score(test_labels, xgb_upsmpl_mdl_pred), precision_score(test_labels, xgb_upsmpl_mdl_pred), f1_score(test_labels, xgb_upsmpl_mdl_pred), roc_auc_score(test_labels, xgb_upsmpl_mdl_pred), confusion_matrix(test_labels, xgb_upsmpl_mdl_pred)],\n",
    "                                index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\", \"confusion_matrix\"],\n",
    "                                columns=['XGB_Upsampled_Score'])\n",
    "\n",
    "xgb_upsmpl_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR_Upsampled_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.625788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.557576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0528736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.0965879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.592951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[2786, 1648], [73, 92]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        LR_Upsampled_Score\n",
       "accuracy                          0.625788\n",
       "recall                            0.557576\n",
       "precision                        0.0528736\n",
       "f1_score                         0.0965879\n",
       "roc_auc_score                     0.592951\n",
       "confusion_matrix  [[2786, 1648], [73, 92]]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Oversampled Modeling: Logistic Regression\n",
    "lr_upsampled = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# train model\n",
    "lr_upsampled_mdl = lr_upsampled.fit(upsmpl_train_features, upsmpl_train_labels)\n",
    "\n",
    "\n",
    "# test model\n",
    "lr_upsampled_pred = lr_upsampled_mdl.predict(test_features)\n",
    "\n",
    "# performance matrix\n",
    "lr_upsmpl_matrix = pd.DataFrame(data=[accuracy_score(test_labels, lr_upsampled_pred), recall_score(test_labels, lr_upsampled_pred), precision_score(test_labels, lr_upsampled_pred), f1_score(test_labels, lr_upsampled_pred), roc_auc_score(test_labels, lr_upsampled_pred), confusion_matrix(test_labels, lr_upsampled_pred)],\n",
    "                                index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\", \"confusion_matrix\"],\n",
    "                                columns=['LR_Upsampled_Score'])\n",
    "\n",
    "lr_upsmpl_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.625788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.557576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.052874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.592951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Score\n",
       "accuracy       0.625788\n",
       "recall         0.557576\n",
       "precision      0.052874\n",
       "roc_auc_score  0.592951"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression threshold\n",
    "\n",
    "threshold = .5 # change the threshold here (default is 0.5)\n",
    "\n",
    "preds = np.where(lr_upsampled_mdl.predict_proba(test_features)[:,1] > threshold, 1, 0) # classifies test features above the threshold as class 1 (exit group)\n",
    "\n",
    "pd.DataFrame(data=[accuracy_score(test_labels, preds), recall_score(test_labels, preds),\n",
    "                   precision_score(test_labels, preds), roc_auc_score(test_labels, preds)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"roc_auc_score\"], columns=['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "School_Charter 0.7839476202589073\n",
      "AvgFirstMonthSalNoMissing -0.5965414622175637\n",
      "Grade_Unknown -0.4428811675974988\n",
      "Urbanicity_Both 0.4196520893928425\n",
      "PellGrantYes 0.41347141157740175\n",
      "School_Public 0.3650839758363922\n",
      "Urbanicity_Rural 0.35286575515413693\n",
      "PellGrantNoOrMissing 0.34461812835585137\n",
      "CertProgramCostNoMissing 0.3357241094308606\n",
      "Region_Small -0.3342872978764283\n",
      "LIC_Served_Yes 0.3242550662809413\n",
      "AttendLIC_HS_No 0.3077260846905743\n",
      "Grade_LOWELEM 0.30652295328980567\n",
      "LIC_Served_No_Or_Unknown -0.30106249029601106\n",
      "LGB_LocalProtect 0.23166901308496482\n",
      "Eth_Black 0.22500361936163166\n",
      "CalcJunior 0.21802036537296285\n",
      "AgeAtFDOSNoMissing 0.21636816696422\n",
      "CMsInSchoolNoMissing 0.19704090238355737\n",
      "HadFamRespNo 0.18552996840667116\n",
      "DeferralNotRequested 0.17257118683325454\n",
      "Grade_HIGH 0.17237373495119251\n",
      "GrewUpLIC_Yes 0.16404910024157396\n",
      "Eth_OtherOrUnknown 0.1632073143025365\n",
      "Region_Medium 0.16252763135790674\n",
      "HadFamRespYes 0.16140093262783775\n",
      "AttendLIC_HS_Unknown 0.16136006131294542\n",
      "COL_High -0.1603081980944374\n",
      "LGB_NoProtect -0.1582461644907613\n",
      "RentPropNoMissing -0.15621717956362763\n",
      "TeacherPP_No 0.145989547625441\n",
      "CalcProfessional -0.1439250176140528\n",
      "GenderFemale 0.14200062088247628\n",
      "CSI12NoMissing -0.14022899710820186\n",
      "Title1No -0.1401156409765517\n",
      "COL_Medium 0.1350673418245604\n",
      "VarsitySport_Yes 0.13451285808384317\n",
      "MajorTeaching_Mismatch 0.13408293975611757\n",
      "DaysTSubmitNoMissing -0.13349504427036163\n",
      "Grade_MIDDLE -0.12517865203306838\n",
      "TeacherPP_Yes 0.12517176104759986\n",
      "CLI8NoMissing -0.1234346037878867\n",
      "OtherCMsSameCoachNoMissing 0.12281922708633003\n",
      "MajorTeaching_Match 0.11380948311995573\n",
      "VarsitySport_No_Or_Unknown 0.11337956478857551\n",
      "COL_Low 0.11282508104996845\n",
      "CSI5NoMissing -0.09830494479215778\n",
      "Grade_UPPERELEM -0.09317402978443978\n",
      "Eth_AsianAmPacIsl -0.09123383982151359\n",
      "AttendLIC_HS_Yes 0.08653236156339496\n",
      "HadFamRespNull 0.08649149024690662\n",
      "Eth_White 0.08468510857017288\n",
      "GrewUpLIC_No_Or_Unknown 0.08384332263480643\n",
      "CLI6NoMissing 0.08318260568640512\n",
      "Eth_Native 0.07709548011211853\n",
      "DeferralRequested 0.07532123604454266\n",
      "K12TeachNo 0.07229600688147134\n",
      "YearsSchoolPartnerNoMissing -0.07228961347071029\n",
      "PerseveranceNoMissing -0.0700900378989071\n",
      "SchoolSelectivityNoMissing -0.06655249652674855\n",
      "K12TeachNull 0.06629912589033596\n",
      "YearsPartnerPartnerNoMissing 0.06551033410507646\n",
      "RegPrefLevNoMissing -0.06397617972446173\n",
      "CalcUnknown -0.05753574144290995\n",
      "Urbanicity_Urban 0.0553348658213339\n",
      "OtherCMsPrevCoachNoMissing 0.05277718890764788\n",
      "Title1Yes 0.04257482116000702\n",
      "School_Other 0.04105461153554633\n",
      "FinalAchievementNoMissing 0.03948677414571715\n",
      "CMProspectRatingNoMissing 0.03856370142696829\n",
      "CommAndPresNoMissing -0.038310779686963926\n",
      "CSI6NoMissing -0.038010211740417604\n",
      "PredModelScoreNoMissing -0.03704619600818105\n",
      "AvgRentNoMissing 0.03420172744414192\n",
      "GenderMale 0.03186888438650772\n",
      "Eth_MultiEthMultiRacial 0.029426847269123035\n",
      "Region_Large -0.023268885794414853\n",
      "CSI3NoMissing -0.019771765608044785\n",
      "LGB_StateProtect 0.016223409792960178\n",
      "Eth_Latinx -0.015592260030394371\n",
      "CorpsSizeNoMissing -0.015516737819315052\n",
      "SecondYearsInSchoolNoMissing 0.01439993127608684\n",
      "RelationshipBuildingNoMissing -0.01205150530465839\n",
      "FRPLNoMissing 0.01145222735105169\n",
      "FirstYearsInSchoolNoMissing -0.011166924963192526\n",
      "FitNoMissing 0.008911967306175054\n",
      "Grade_ECE -0.008284793512123854\n",
      "CumuGPANoMissing -0.007658347717455497\n",
      "YearsAsCoach 0.00584854393107378\n",
      "K12TeachYes -0.00393667142132712\n",
      "CalcUndergrad -0.002297920369188274\n",
      "CalcGradStudent -7.243015247583183e-05\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Umsampled Model Feature Importance\n",
    "\n",
    "importance = lr_upsampled_mdl.coef_[0]\n",
    "feature_dict = {}\n",
    "for v, n in zip(importance, req_vars[1:]): #zipping the feature importance by the magnitude of their coefficients\n",
    "    feature_dict[n] = v\n",
    "for k, v in sorted(feature_dict.items(), key=lambda item: abs(item[1]), reverse=True):\n",
    "    print(k, v)\n",
    "\n",
    "# exporting the dictionary to CSV file\n",
    "pd.DataFrame.from_dict(feature_dict, orient='index').to_csv('Logistic_Regression_Feature_Importance_Scaled_DF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.650330\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prastha/opt/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Summary Table (to get statistical significance of all features) \n",
    "\n",
    "# training the model\n",
    "\n",
    "lr2 = sm.add_constant(upsmpl_train_features) # add constant to the regression line\n",
    "lr2 = sm.Logit(upsmpl_train_labels, upsmpl_train_features).fit(cov_type='HC1') # account for heteroskedasticity\n",
    "lr2_summary = lr2.summary() # summary table of the regression results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting the summary table to CSV\n",
    "lr2_as_html = lr2_summary.tables[1].as_html() # convert the table into an HTML file\n",
    "\n",
    "lr2_pd = pd.read_html(lr2_as_html, header=0, index_col=0)[0] # HTML file as pandas dataframe\n",
    "\n",
    "lr2_pd = lr2_pd.sort_values(by = ['P>|z|']) # sort the dataframe in increasing order of p-values\n",
    "                                            # meaning most statistically significant at first\n",
    "\n",
    "lr2_pd.to_csv(\"Logistic_Regression_Table_Scaled_DF.csv\") #export the df to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    731\n",
       "0    731\n",
       "Name: SwellOneExit, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## -- UNDERSAMPLING -- ##\n",
    "\n",
    "df_undsmpl = pd.concat([train_features, train_labels], axis=1)\n",
    "\n",
    "\n",
    "df_undsmpl_majority = df_undsmpl[df_undsmpl.SwellOneExit==0]\n",
    "df_undsmpl_minority = df_undsmpl[df_undsmpl.SwellOneExit==1]\n",
    "\n",
    "# undersample majority class\n",
    "df_majority_undsampled = resample(df_undsmpl_majority, \n",
    "                                 replace=False,     # sample without replacement\n",
    "                                 n_samples=len(df_undsmpl_minority),    # to match minority class\n",
    "                                 random_state=123) # for reproducible results\n",
    " \n",
    "# combine minority class with undersampled majority class\n",
    "df_undsampled = pd.concat([df_majority_undsampled, df_undsmpl_minority]) # undersampled dataframe\n",
    " \n",
    "# display new class counts\n",
    "df_undsampled.SwellOneExit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training test split for undersampled dataframe\n",
    "undsmpl_Y = df_undsampled['SwellOneExit'] # labels\n",
    "undsmpl_X = df_undsampled.drop('SwellOneExit', axis=1) # features\n",
    "\n",
    "undsmpl_train_features, undsmpl_test_features, undsmpl_train_labels, undsmpl_test_labels = train_test_split(undsmpl_X, undsmpl_Y, test_size = 0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB_Downsampled_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.616003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.563636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0520425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.0952869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.590794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[2740, 1694], [72, 93]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     XGB_Downsampled_Score\n",
       "accuracy                          0.616003\n",
       "recall                            0.563636\n",
       "precision                        0.0520425\n",
       "f1_score                         0.0952869\n",
       "roc_auc_score                     0.590794\n",
       "confusion_matrix  [[2740, 1694], [72, 93]]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undersampled Modeling: XGBoost\n",
    "\n",
    "xgb_undsmpl_model = xgb.XGBClassifier()\n",
    "xgb_undsmpl_model.fit(undsmpl_train_features, undsmpl_train_labels) # training the model\n",
    "\n",
    "xgb_undsmpl_model_pred = xgb_undsmpl_model.predict(test_features) # testing the model\n",
    "\n",
    "# performance matrix\n",
    "xgb_dwnsmpl_matrix = pd.DataFrame(data=[accuracy_score(test_labels, xgb_undsmpl_model_pred), recall_score(test_labels, xgb_undsmpl_model_pred), precision_score(test_labels, xgb_undsmpl_model_pred), f1_score(test_labels, xgb_undsmpl_model_pred), roc_auc_score(test_labels, xgb_undsmpl_model_pred), confusion_matrix(test_labels, xgb_undsmpl_model_pred)],\n",
    "                                index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\", \"confusion_matrix\"],\n",
    "                                columns=['XGB_Downsampled_Score'])\n",
    "\n",
    "xgb_dwnsmpl_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF_Downsampled_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.610133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0547046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.100351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.608172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[2706, 1728], [65, 100]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       RF_Downsampled_Score\n",
       "accuracy                           0.610133\n",
       "recall                             0.606061\n",
       "precision                         0.0547046\n",
       "f1_score                           0.100351\n",
       "roc_auc_score                      0.608172\n",
       "confusion_matrix  [[2706, 1728], [65, 100]]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undersampled Modeling: Random Forest\n",
    "\n",
    "rf_downsampled = RandomForestClassifier(n_estimators = 1000, random_state=0, n_jobs=-1)\n",
    "\n",
    "# train model\n",
    "rf_downsampled_mdl = rf_downsampled.fit(undsmpl_train_features, undsmpl_train_labels)\n",
    "\n",
    "# test model\n",
    "rf_downsampled_pred = rf_downsampled_mdl.predict(test_features)\n",
    "\n",
    "rf_dwnsmpl_matrix = pd.DataFrame(data=[accuracy_score(test_labels, rf_downsampled_pred), recall_score(test_labels, rf_downsampled_pred), precision_score(test_labels, rf_downsampled_pred), f1_score(test_labels, rf_downsampled_pred), roc_auc_score(test_labels, rf_downsampled_pred), confusion_matrix(test_labels, rf_downsampled_pred)],\n",
    "                                index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\", \"confusion_matrix\"],\n",
    "                                columns=['RF_Downsampled_Score'])\n",
    "\n",
    "rf_dwnsmpl_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance for RF Undersampling \n",
    "\n",
    "rf_importance = rf_downsampled_mdl.feature_importances_\n",
    "    \n",
    "rf_feature_dict = {}\n",
    "for v, n in zip(rf_importance, req_vars[1:]):\n",
    "    rf_feature_dict[n] = v\n",
    "\n",
    "rf_importance_df = pd.DataFrame.from_dict(rf_feature_dict, orient='index') # create a pandas df from the dictionary\n",
    "\n",
    "rf_importance_df.columns = ['Feature Importance']\n",
    "\n",
    "rf_importance_df = rf_importance_df.sort_values(by = ['Feature Importance'], ascending=False) # sort the df by feature importance in descending order\n",
    "\n",
    "rf_importance_df.to_csv(\"RF_Undersampled_Feature_Importance_Scaled_DF.csv\") # export the df to csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR_Downsampled_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.588606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.0947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.594091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[2608, 1826], [66, 99]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      LR_Downsampled_Score\n",
       "accuracy                          0.588606\n",
       "recall                                 0.6\n",
       "precision                        0.0514286\n",
       "f1_score                         0.0947368\n",
       "roc_auc_score                     0.594091\n",
       "confusion_matrix  [[2608, 1826], [66, 99]]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undersampled Modeling: Logistic Regression\n",
    "\n",
    "# logistic regression\n",
    "lr_undsampled = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# train model\n",
    "lr_undsampled_mdl = lr_undsampled.fit(undsmpl_train_features, undsmpl_train_labels)\n",
    "\n",
    "# test model\n",
    "lr_undsampled_pred = lr_undsampled_mdl.predict(test_features)\n",
    "\n",
    "lr_dwnsmpl_matrix = pd.DataFrame(data=[accuracy_score(test_labels, lr_undsampled_pred), recall_score(test_labels, lr_undsampled_pred), precision_score(test_labels, lr_undsampled_pred), f1_score(test_labels, lr_undsampled_pred), roc_auc_score(test_labels, lr_undsampled_pred), confusion_matrix(test_labels, lr_undsampled_pred)],\n",
    "                                index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\", \"confusion_matrix\"],\n",
    "                                columns=['LR_Downsampled_Score'])\n",
    "\n",
    "lr_dwnsmpl_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.620648\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prastha/opt/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Summary Stats (for Undersampling)\n",
    "\n",
    "# training the model\n",
    "\n",
    "lr2_undsmpl_mdl = sm.add_constant(undsmpl_train_features)\n",
    "lr2_undsmpl_mdl = sm.Logit(undsmpl_train_labels, undsmpl_train_features).fit(cov_type='HC1')\n",
    "lr2_undsmpl_mdl_summary = lr2_undsmpl_mdl.summary()\n",
    "\n",
    "# exporting the model to CSV\n",
    "lr2_undsmpl_mdl_as_html = lr2_undsmpl_mdl_summary.tables[1].as_html()\n",
    "lr2_undsmpl_mdl_pd = pd.read_html(lr2_undsmpl_mdl_as_html, header=0, index_col=0)[0]\n",
    "\n",
    "lr2_undsmpl_mdl_pd = lr2_undsmpl_mdl_pd.sort_values(by = ['P>|z|'])\n",
    "\n",
    "# lr2_pd.to_csv(\"Logistic_Regression_Table.csv\")\n",
    "\n",
    "lr2_undsmpl_mdl_pd.to_csv(\"Logistic_Regression_Undersampled_Table_Scaled_DF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Matrix of All Matrices in a spreadsheet\n",
    "\n",
    "mdl_matrices = [xgb_matrix, rf_upsmpl_matrix, lr_upsmpl_matrix, xgb_upsmpl_matrix, rf_dwnsmpl_matrix, lr_dwnsmpl_matrix, xgb_dwnsmpl_matrix]\n",
    "\n",
    "pd.concat(mdl_matrices, axis=1).to_csv(\"Performance_Matrix_of_All_Models_Scaled_DF.csv\") # concatinating all dfs and exporting to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">LR_Upsampled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.648402</td>\n",
       "      <td>0.627093</td>\n",
       "      <td>0.6505</td>\n",
       "      <td>0.638973</td>\n",
       "      <td>0.644193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0561728</td>\n",
       "      <td>0.0555877</td>\n",
       "      <td>0.0486726</td>\n",
       "      <td>0.0579104</td>\n",
       "      <td>0.0587523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.50838</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.430168</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>0.541899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.101167</td>\n",
       "      <td>0.100682</td>\n",
       "      <td>0.0874503</td>\n",
       "      <td>0.104639</td>\n",
       "      <td>0.106011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[2891, 1529], [88, 91]]</td>\n",
       "      <td>[[2788, 1631], [84, 96]]</td>\n",
       "      <td>[[2914, 1505], [102, 77]]</td>\n",
       "      <td>[[2841, 1578], [82, 97]]</td>\n",
       "      <td>[[2865, 1554], [82, 97]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              LR_Upsampled                            \\\n",
       "                                         0                         1   \n",
       "accuracy                          0.648402                  0.627093   \n",
       "precision                        0.0561728                 0.0555877   \n",
       "recall                             0.50838                  0.533333   \n",
       "f1                                0.101167                  0.100682   \n",
       "confusion_matrix  [[2891, 1529], [88, 91]]  [[2788, 1631], [84, 96]]   \n",
       "\n",
       "                                                                       \\\n",
       "                                          2                         3   \n",
       "accuracy                             0.6505                  0.638973   \n",
       "precision                         0.0486726                 0.0579104   \n",
       "recall                             0.430168                  0.541899   \n",
       "f1                                0.0874503                  0.104639   \n",
       "confusion_matrix  [[2914, 1505], [102, 77]]  [[2841, 1578], [82, 97]]   \n",
       "\n",
       "                                            \n",
       "                                         4  \n",
       "accuracy                          0.644193  \n",
       "precision                        0.0587523  \n",
       "recall                            0.541899  \n",
       "f1                                0.106011  \n",
       "confusion_matrix  [[2865, 1554], [82, 97]]  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validation with Logistic Regression with Upsampled Dataframe\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "X = df.drop('SwellOneExit',axis=1)\n",
    "Y = df['SwellOneExit']\n",
    "\n",
    "lr_upsmpl_cv_acc_score_list = []\n",
    "lr_upsmpl_cv_recall_list = []\n",
    "lr_upsmpl_cv_precision_list = []\n",
    "lr_upsmpl_cv_f1_list = []\n",
    "lr_upsmpl_cv_confusion_list = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    train_features, test_features = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    train_labels, test_labels = Y[train_index], Y[test_index]\n",
    "    \n",
    "    df_ovsmpl = pd.concat([train_features, train_labels], axis=1)\n",
    "    df_majority = df_ovsmpl[df_ovsmpl.SwellOneExit==0]\n",
    "    df_minority = df_ovsmpl[df_ovsmpl.SwellOneExit==1]\n",
    "    \n",
    "    # Upsample minority class\n",
    "    df_minority_upsampled = resample(df_minority, \n",
    "                                     replace=True,     # sample with replacement\n",
    "                                     n_samples=len(df_majority),    # to match majority class\n",
    "                                     random_state=123) # reproducible results\n",
    "    # Combine majority class with upsampled minority class\n",
    "    df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "    upsmpl_Y = df_upsampled['SwellOneExit']\n",
    "    upsmpl_X = df_upsampled.drop('SwellOneExit', axis=1)\n",
    "\n",
    "\n",
    "    lr_upsampled = LogisticRegression(solver='liblinear')\n",
    "\n",
    "    # train model\n",
    "    lr_upsampled_mdl = lr_upsampled.fit(upsmpl_X, upsmpl_Y)\n",
    "    \n",
    "    # test model\n",
    "    lr_upsampled_pred = lr_upsampled_mdl.predict(test_features)\n",
    "    \n",
    "    # performance matrix\n",
    "    lr_upsmpl_cv_acc_score_list.append(accuracy_score(test_labels, lr_upsampled_pred))\n",
    "    lr_upsmpl_cv_precision_list.append(precision_score(test_labels, lr_upsampled_pred))\n",
    "    lr_upsmpl_cv_recall_list.append(recall_score(test_labels, lr_upsampled_pred))\n",
    "    lr_upsmpl_cv_f1_list.append(f1_score(test_labels, lr_upsampled_pred))\n",
    "    lr_upsmpl_cv_confusion_list.append(confusion_matrix(test_labels, lr_upsampled_pred))\n",
    "\n",
    "    lr_upsmpl_cv = pd.DataFrame(data=[lr_upsmpl_cv_acc_score_list, lr_upsmpl_cv_precision_list, lr_upsmpl_cv_recall_list, lr_upsmpl_cv_f1_list, lr_upsmpl_cv_confusion_list], index=['accuracy', 'precision','recall', 'f1', 'confusion_matrix'])\n",
    "\n",
    "lr_upsmpl_cv.columns = pd.MultiIndex.from_tuples(zip(['LR_Upsampled', 'LR_Upsampled', 'LR_Upsampled', 'LR_Upsampled', 'LR_Upsampled'], lr_upsmpl_cv.columns))\n",
    "\n",
    "lr_upsmpl_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prastha/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/prastha/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/prastha/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">LR_Downsampled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.648402</td>\n",
       "      <td>0.627093</td>\n",
       "      <td>0.6505</td>\n",
       "      <td>0.638973</td>\n",
       "      <td>0.644193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0561728</td>\n",
       "      <td>0.0555877</td>\n",
       "      <td>0.0486726</td>\n",
       "      <td>0.0579104</td>\n",
       "      <td>0.0587523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.50838</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.430168</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>0.541899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.101167</td>\n",
       "      <td>0.100682</td>\n",
       "      <td>0.0874503</td>\n",
       "      <td>0.104639</td>\n",
       "      <td>0.106011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[2891, 1529], [88, 91]]</td>\n",
       "      <td>[[2788, 1631], [84, 96]]</td>\n",
       "      <td>[[2914, 1505], [102, 77]]</td>\n",
       "      <td>[[2841, 1578], [82, 97]]</td>\n",
       "      <td>[[2865, 1554], [82, 97]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            LR_Downsampled                            \\\n",
       "                                         0                         1   \n",
       "accuracy                          0.648402                  0.627093   \n",
       "precision                        0.0561728                 0.0555877   \n",
       "recall                             0.50838                  0.533333   \n",
       "f1                                0.101167                  0.100682   \n",
       "confusion_matrix  [[2891, 1529], [88, 91]]  [[2788, 1631], [84, 96]]   \n",
       "\n",
       "                                                                       \\\n",
       "                                          2                         3   \n",
       "accuracy                             0.6505                  0.638973   \n",
       "precision                         0.0486726                 0.0579104   \n",
       "recall                             0.430168                  0.541899   \n",
       "f1                                0.0874503                  0.104639   \n",
       "confusion_matrix  [[2914, 1505], [102, 77]]  [[2841, 1578], [82, 97]]   \n",
       "\n",
       "                                            \n",
       "                                         4  \n",
       "accuracy                          0.644193  \n",
       "precision                        0.0587523  \n",
       "recall                            0.541899  \n",
       "f1                                0.106011  \n",
       "confusion_matrix  [[2865, 1554], [82, 97]]  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validation with Logistic Regression with Downsampled Dataframe\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "X = df.drop('SwellOneExit',axis=1)\n",
    "Y = df['SwellOneExit']\n",
    "\n",
    "lr_dwnsmpl_cv_acc_score_list = []\n",
    "lr_dwnsmpl_cv_recall_list = []\n",
    "lr_dwnsmpl_cv_precision_list = []\n",
    "lr_dwnsmpl_cv_f1_list = []\n",
    "lr_dwnsmpl_cv_confusion_list = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    train_features, test_features = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    train_labels, test_labels = Y[train_index], Y[test_index]\n",
    "    \n",
    "    df_downsampled = pd.concat([train_features, train_labels], axis=1)\n",
    "    df_majority = df_downsampled[df_downsampled.SwellOneExit==0]\n",
    "    df_minority = df_downsampled[df_downsampled.SwellOneExit==1]\n",
    "    \n",
    "    # Upsample minority class\n",
    "    df_majority_downsampled = resample(df_majority, \n",
    "                                     replace=False,     # sample without replacement\n",
    "                                     n_samples=len(df_minority),    # to match minority class\n",
    "                                     random_state=123) # for reproducible results\n",
    "    \n",
    "    # Combine majority class with downsampled majority class\n",
    "    df_upsampled = pd.concat([df_minority, df_majority_downsampled])\n",
    "    dwnsmpl_Y = df_downsampled['SwellOneExit']\n",
    "    dwnsmpl_X = df_downsampled.drop('SwellOneExit', axis=1)\n",
    "\n",
    "\n",
    "    lr_downsampled = LogisticRegression(solver='liblinear')\n",
    "\n",
    "    # train model\n",
    "    lr_downsampled_mdl = lr_downsampled.fit(dwnsmpl_X, dwnsmpl_Y)\n",
    "    \n",
    "    # test model\n",
    "    lr_downsampled_pred = lr_downsampled_mdl.predict(test_features)\n",
    "    \n",
    "    # performance matrix\n",
    "    lr_dwnsmpl_cv_acc_score_list.append(accuracy_score(test_labels, lr_downsampled_pred))\n",
    "    lr_dwnsmpl_cv_precision_list.append(precision_score(test_labels, lr_downsampled_pred))\n",
    "    lr_dwnsmpl_cv_recall_list.append(recall_score(test_labels, lr_downsampled_pred))\n",
    "    lr_dwnsmpl_cv_f1_list.append(f1_score(test_labels, lr_downsampled_pred))\n",
    "    lr_dwnsmpl_cv_confusion_list.append(confusion_matrix(test_labels, lr_downsampled_pred))\n",
    "\n",
    "    lr_dwnsmpl_cv = pd.DataFrame(data=[lr_upsmpl_cv_acc_score_list, lr_upsmpl_cv_precision_list, lr_upsmpl_cv_recall_list, lr_upsmpl_cv_f1_list, lr_upsmpl_cv_confusion_list], index=['accuracy', 'precision','recall', 'f1', 'confusion_matrix'])\n",
    "\n",
    "lr_dwnsmpl_cv.columns = pd.MultiIndex.from_tuples(zip(['LR_Downsampled', 'LR_Downsampled', 'LR_Downsampled', 'LR_Downsampled', 'LR_Downsampled'], lr_dwnsmpl_cv.columns))\n",
    "\n",
    "lr_dwnsmpl_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prastha/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/prastha/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/prastha/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">RF_Upsampled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.961078</td>\n",
       "      <td>0.960861</td>\n",
       "      <td>0.960635</td>\n",
       "      <td>0.960853</td>\n",
       "      <td>0.96107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[4420, 0], [179, 0]]</td>\n",
       "      <td>[[4419, 0], [180, 0]]</td>\n",
       "      <td>[[4417, 2], [179, 0]]</td>\n",
       "      <td>[[4418, 1], [179, 0]]</td>\n",
       "      <td>[[4419, 0], [179, 0]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           RF_Upsampled                         \\\n",
       "                                      0                      1   \n",
       "accuracy                       0.961078               0.960861   \n",
       "precision                             0                      0   \n",
       "recall                                0                      0   \n",
       "f1                                    0                      0   \n",
       "confusion_matrix  [[4420, 0], [179, 0]]  [[4419, 0], [180, 0]]   \n",
       "\n",
       "                                                                \\\n",
       "                                      2                      3   \n",
       "accuracy                       0.960635               0.960853   \n",
       "precision                             0                      0   \n",
       "recall                                0                      0   \n",
       "f1                                    0                      0   \n",
       "confusion_matrix  [[4417, 2], [179, 0]]  [[4418, 1], [179, 0]]   \n",
       "\n",
       "                                         \n",
       "                                      4  \n",
       "accuracy                        0.96107  \n",
       "precision                             0  \n",
       "recall                                0  \n",
       "f1                                    0  \n",
       "confusion_matrix  [[4419, 0], [179, 0]]  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validation with Random Forest with Upsampled Dataframe\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "X = df.drop('SwellOneExit',axis=1)\n",
    "Y = df['SwellOneExit']\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X, Y, test_size = 0.2, random_state=123)\n",
    "\n",
    "rf_upsmpl_cv_acc_score_list = []\n",
    "rf_upsmpl_cv_recall_list = []\n",
    "rf_upsmpl_cv_precision_list = []\n",
    "rf_upsmpl_cv_f1_list = []\n",
    "rf_upsmpl_cv_confusion_list = []\n",
    "\n",
    "for rf_train_index, rf_test_index in skf.split(X, Y):\n",
    "    rf_train_features, rf_test_features = X.iloc[rf_train_index, :], X.iloc[rf_test_index, :]\n",
    "    rf_train_labels, rf_test_labels = Y[rf_train_index], Y[rf_test_index]\n",
    "    \n",
    "    rf_df_ovsmpl = pd.concat([rf_train_features, rf_train_labels], axis=1)\n",
    "    rf_df_majority = rf_df_ovsmpl[rf_df_ovsmpl.SwellOneExit==0]\n",
    "    rf_df_minority = rf_df_ovsmpl[rf_df_ovsmpl.SwellOneExit==1]\n",
    "    \n",
    "    # Upsample minority class\n",
    "    rf_df_minority_upsampled = resample(rf_df_minority, \n",
    "                                     replace=True,     # sample with replacement\n",
    "                                     n_samples=len(df_majority),    # to match majority class\n",
    "                                     random_state=123) # reproducible results\n",
    "    # Combine majority class with upsampled minority class\n",
    "    rf_df_upsampled = pd.concat([rf_df_majority, rf_df_minority_upsampled])\n",
    "    rf_upsmpl_Y = rf_df_upsampled['SwellOneExit']\n",
    "    rf_upsmpl_X = rf_df_upsampled.drop('SwellOneExit', axis=1)\n",
    "\n",
    "\n",
    "    \n",
    "    rf_cv_upsampled = RandomForestClassifier(n_estimators = 1000, random_state=0, n_jobs=-1)\n",
    "\n",
    "    # train model\n",
    "    rf_cv_upsampled_mdl = rf_cv_upsampled.fit(rf_upsmpl_X, rf_upsmpl_Y)\n",
    "\n",
    "    # test model\n",
    "    rf_cv_upsampled_pred = rf_cv_upsampled_mdl.predict(rf_test_features) # testing on the test features from the original dataframe\n",
    "\n",
    "    rf_upsmpl_cv_acc_score_list.append(accuracy_score(rf_test_labels, rf_cv_upsampled_pred))\n",
    "    rf_upsmpl_cv_precision_list.append(precision_score(rf_test_labels, rf_cv_upsampled_pred))\n",
    "    rf_upsmpl_cv_recall_list.append(recall_score(rf_test_labels, rf_cv_upsampled_pred))\n",
    "    rf_upsmpl_cv_f1_list.append(f1_score(rf_test_labels, rf_cv_upsampled_pred))\n",
    "    rf_upsmpl_cv_confusion_list.append(confusion_matrix(rf_test_labels, rf_cv_upsampled_pred))\n",
    "\n",
    "    rf_upsmpl_cv = pd.DataFrame(data=[rf_upsmpl_cv_acc_score_list, rf_upsmpl_cv_precision_list, rf_upsmpl_cv_recall_list, rf_upsmpl_cv_f1_list, rf_upsmpl_cv_confusion_list], index=['accuracy', 'precision','recall', 'f1', 'confusion_matrix'])\n",
    "\n",
    "rf_upsmpl_cv.columns = pd.MultiIndex.from_tuples(zip(['RF_Upsampled', 'RF_Upsampled', 'RF_Upsampled', 'RF_Upsampled', 'RF_Upsampled'], rf_upsmpl_cv.columns))\n",
    "\n",
    "rf_upsmpl_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">RF_Downsampled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.610785</td>\n",
       "      <td>0.62992</td>\n",
       "      <td>0.607003</td>\n",
       "      <td>0.603741</td>\n",
       "      <td>0.614615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0542335</td>\n",
       "      <td>0.0596065</td>\n",
       "      <td>0.0561614</td>\n",
       "      <td>0.0542594</td>\n",
       "      <td>0.0592142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.547486</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.575419</td>\n",
       "      <td>0.558659</td>\n",
       "      <td>0.597765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.0986908</td>\n",
       "      <td>0.107966</td>\n",
       "      <td>0.102335</td>\n",
       "      <td>0.098912</td>\n",
       "      <td>0.107754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[2711, 1709], [81, 98]]</td>\n",
       "      <td>[[2794, 1625], [77, 103]]</td>\n",
       "      <td>[[2688, 1731], [76, 103]]</td>\n",
       "      <td>[[2676, 1743], [79, 100]]</td>\n",
       "      <td>[[2719, 1700], [72, 107]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            RF_Downsampled                             \\\n",
       "                                         0                          1   \n",
       "accuracy                          0.610785                    0.62992   \n",
       "precision                        0.0542335                  0.0596065   \n",
       "recall                            0.547486                   0.572222   \n",
       "f1                               0.0986908                   0.107966   \n",
       "confusion_matrix  [[2711, 1709], [81, 98]]  [[2794, 1625], [77, 103]]   \n",
       "\n",
       "                                                                        \\\n",
       "                                          2                          3   \n",
       "accuracy                           0.607003                   0.603741   \n",
       "precision                         0.0561614                  0.0542594   \n",
       "recall                             0.575419                   0.558659   \n",
       "f1                                 0.102335                   0.098912   \n",
       "confusion_matrix  [[2688, 1731], [76, 103]]  [[2676, 1743], [79, 100]]   \n",
       "\n",
       "                                             \n",
       "                                          4  \n",
       "accuracy                           0.614615  \n",
       "precision                         0.0592142  \n",
       "recall                             0.597765  \n",
       "f1                                 0.107754  \n",
       "confusion_matrix  [[2719, 1700], [72, 107]]  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validation with Random Forest with Downsampled Dataframe\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "X = df.drop('SwellOneExit',axis=1)\n",
    "Y = df['SwellOneExit']\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X, Y, test_size = 0.2, random_state=123)\n",
    "\n",
    "rf_dwnsmpl_cv_acc_score_list = []\n",
    "rf_dwnsmpl_cv_recall_list = []\n",
    "rf_dwnsmpl_cv_precision_list = []\n",
    "rf_dwnsmpl_cv_f1_list = []\n",
    "rf_dwnsmpl_cv_confusion_list = []\n",
    "\n",
    "for rf_train_index, rf_test_index in skf.split(X, Y):\n",
    "    rf_train_features, rf_test_features = X.iloc[rf_train_index, :], X.iloc[rf_test_index, :]\n",
    "    rf_train_labels, rf_test_labels = Y[rf_train_index], Y[rf_test_index]\n",
    "\n",
    "    rf_df_dwnsmpl = pd.concat([rf_train_features, rf_train_labels], axis=1)\n",
    "    rf_df_majority = rf_df_dwnsmpl[rf_df_dwnsmpl.SwellOneExit==0]\n",
    "    rf_df_minority = rf_df_dwnsmpl[rf_df_dwnsmpl.SwellOneExit==1]\n",
    "\n",
    "    # Upsample minority class\n",
    "    rf_df_majority_downsampled = resample(rf_df_majority,\n",
    "                                     replace=False,     # sample with replacement\n",
    "                                     n_samples=len(df_minority),    # to match majority class\n",
    "                                     random_state=123) # reproducible results\n",
    "    # Combine minority class with downsampled majority class\n",
    "    rf_df_downsampled = pd.concat([rf_df_minority, rf_df_majority_downsampled])\n",
    "    rf_dwnsmpl_Y = rf_df_downsampled['SwellOneExit']\n",
    "    rf_dwnsmpl_X = rf_df_downsampled.drop('SwellOneExit', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    rf_cv_downsampled = RandomForestClassifier(n_estimators = 1000, random_state=0, n_jobs=-1)\n",
    "\n",
    "    # train model\n",
    "    rf_cv_downsampled_mdl = rf_cv_downsampled.fit(rf_dwnsmpl_X, rf_dwnsmpl_Y)\n",
    "\n",
    "    # test model\n",
    "    rf_cv_downsampled_pred = rf_cv_downsampled_mdl.predict(rf_test_features) # testing on the test features from the original dataframe\n",
    "\n",
    "    rf_dwnsmpl_cv_acc_score_list.append(accuracy_score(rf_test_labels, rf_cv_downsampled_pred))\n",
    "    rf_dwnsmpl_cv_precision_list.append(precision_score(rf_test_labels, rf_cv_downsampled_pred))\n",
    "    rf_dwnsmpl_cv_recall_list.append(recall_score(rf_test_labels, rf_cv_downsampled_pred))\n",
    "    rf_dwnsmpl_cv_f1_list.append(f1_score(rf_test_labels, rf_cv_downsampled_pred))\n",
    "    rf_dwnsmpl_cv_confusion_list.append(confusion_matrix(rf_test_labels, rf_cv_downsampled_pred))\n",
    "\n",
    "    rf_dwnsmpl_cv = pd.DataFrame(data=[rf_dwnsmpl_cv_acc_score_list, rf_dwnsmpl_cv_precision_list, rf_dwnsmpl_cv_recall_list, rf_dwnsmpl_cv_f1_list, rf_dwnsmpl_cv_confusion_list], index=['accuracy', 'precision','recall', 'f1', 'confusion_matrix'])\n",
    "\n",
    "rf_dwnsmpl_cv.columns = pd.MultiIndex.from_tuples(zip(['RF_Downsampled', 'RF_Downsampled', 'RF_Downsampled', 'RF_Downsampled', 'RF_Downsampled'], rf_dwnsmpl_cv.columns))\n",
    "\n",
    "rf_dwnsmpl_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the cross validation results in a single dataframe\n",
    "\n",
    "cv_results = lr_upsmpl_cv.join(rf_upsmpl_cv.reindex(lr_upsmpl_cv.index, level=0)) # add LR and RF for upsampled results\n",
    "cv_results = cv_results.join(lr_dwnsmpl_cv.reindex(cv_results.index, level=0))\n",
    "cv_results = cv_results.join(rf_dwnsmpl_cv.reindex(cv_results.index, level=0))\n",
    "\n",
    "cv_results.to_csv('Cross_Validation_Results_Scaled_DF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
